# 一、基础概念篇

## 1、OSI七层模型

**OSI 七层模型** 是国际标准化组织提出一个网络分层模型，其大体结构以及每一层提供的功能如下图所示：

- 物理层：传输比特流（`0101`二进制数据），将比特流转化为电流强弱传输，到达目的后再转化为比特流，即常说的数模转化和模数转换。**这层数据叫做比特。网卡工作在这层。**
- 数据链路层：比特数据组成帧，**交换机**工作在这层，**对帧解码，并根据帧中包含的信息把数据发送到正确的接收方。**该层负责物理层面上**互连的节点之间的通信传输**。例如与1个以太网相连的两个节点间的通讯。常见的协议有 **`HDLC、PPP、SLIP`等**
- 网络层：网络层负责将数据传输到目标地址。目标地址可以使多个网络通过路由器连接而成的某一个地址。因此这一层主要负责**寻址和路由选择**。主要由 `IP、ICMP` 两个协议组成
- 传输层：传输层解决了主机间的数据传输，数据间的传输可以是不同网络，并且传输层解决了**传输质量**的问题。传输层需要关注的协议有TCP/IP协议中的`TCP`协议和`UDP`协议。
- 会话层：会话层作用是**负责建立和断开通信连接**，何时建立，断开连接以及保持多久的连接。常见的协议有 `ADSP、RPC` 等
- 表示层：解决**不同系统之间通信语法问题**，在表示层数据将按照网络能理解的方案进行格式化，格式化因所使用网络的不同而不同。它主要负责数据格式的转换。具体来说，就是讲设备固有的数据格式转换为网络标准格式。常见的协议有`ASCII、SSL/TLS` 等
- 应用层：应用层旨在更**方便应用从网络中接收的数据**，重点关注`TCP/IP`协议中的HTTP协议



<img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/osi-7-model.png" alt="OSI 七层模型" style="zoom:80%;" />

**OSI 的七层体系结构概念清楚，理论也很完整，但是它比较复杂而且不实用，而且有些功能在多个层中重复出现。**

## 2、TCP/IP四层模型

**TCP/IP 四层模型** 是目前被广泛采用的一种模型,我们可以将 TCP / IP 模型看作是 **OSI 七层模型的精简版本**，由以下 4 层组成：

1. **应用层**
2. **传输层**
3. **网络层**
4. **网络接口层**

### I.应用层（Application layer）

应用层位于传输层之上，主要**提供两个终端设备上的应用程序之间`信息交换`的服务**，它定义了信息交换的格式，消息会交给下一层传输层来传输。我们把应用层交互的数据单元称为**报文。**

<img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/application-layer-protocol.png" alt="应用层重要协议" style="zoom:80%;" />

### II.传输层（Transport layer）

传输层的主要任务就是负责向**两台终端设备进程之间的通信提供通用的`数据传输`服务。** 应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。我们将传输层交互的数据单元成为**报文段。**

**运输层主要使用以下两种协议：**

1. **传输控制协议 TCP**（Transmisson Control Protocol）--提供 **面向连接** 的，**可靠的** 数据传输服务。
2. **用户数据协议 UDP**（User Datagram Protocol）--提供 **无连接** 的，尽最大努力的数据传输服务**（不保证数据传输的可靠性）**。

###  III.网络层（Network layer）

**网络层负责为分组交换网上的`不同主机`提供通信服务。** 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 **IP 数据报，简称数据报**。

<img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/nerwork-layer-protocol.png" alt="网络层重要协议" style="zoom:80%;" />

互联网的网络层也叫做 **网际层** 或 **IP 层**。

### IV.网络接口层（Network interface layer）

我们可以把网络接口层看作是**数据链路层和物理层的合体。**

1. 数据链路层(data link layer)通常简称为链路层（ 两台主机之间的数据传输，总是在一段一段的链路上传送的）。**数据链路层的作用是将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。**
2. **物理层的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异**

<img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/network/network-interface-layer-protocol.png" alt="网络接口层重要协议" style="zoom: 80%;" />

## 3、网络设备

### I.网卡(计算机中的硬件)

网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将**数字信息转换为电信号**，才能在网线上传输，也就是说，这才是真正的数据发送过程。**MAC地址就在网卡设备中。**

<img src="https://m.360buyimg.com/mobilecms/s750x750_jfs/t20005/215/587062515/300963/b9942ad8/5afe7ef3Nec057dd8.jpg!q80.dpg" alt="查看源图像" style="zoom:33%;" />

<img src="https://img-blog.csdnimg.cn/a1607854655a4b9c91057ed5e65d8588.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q-P5pel6YO955So5oOF6Iez5rex,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:60%;" />

负责执行这一操作的是**网卡**，要控制网卡还需要靠**网卡驱动程序**。

网卡驱动获取网络包之后，会将其**复制**到网卡内的缓存区中，接着会在其**开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/%E6%95%B0%E6%8D%AE%E5%8C%85.drawio.png" alt="数据包" style="zoom:67%;" />

- 起始帧分界符是一个用来表示包起始位置的标记
- 末尾的 `FCS`（帧校验序列）用来检查包传输过程是否有损坏

最后**网卡会将包转为电信号，通过网线发送出去。**

### II.交换机

**交换机可以接入多台电脑**

**交换机**是基于以太网设计的，俗称**二层**网络设备，交换机的端口**不具有 MAC 地址。**

:green_apple: **交换机可以实现子网内的主机的通信，但无法实现与其它网络互联**

每个电脑网卡的 **MAC 地址**都是不一样的，电脑发送数据时，数据头部携带网卡的 MAC 地址，用 MAC 地址标识来不同的电脑

交换机就可以识别数据头部的 MAC 地址来区分不同的电脑

交换机除了能识别不同的电脑，还需要找到电脑连接的**交换机端口**，才能顺利的把数据从相应端口发送出去

交换机通过**自学机制**，把学习到的设备 MAC 地址和交换机端口号添加到 **MAC 地址表**，并根据 MAC 地址表进行数据**转发**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/23.jpg" alt="交换机的 MAC 地址表" style="zoom:50%;" />

### III.路由器

交换机需要记录的 MAC 地址表也越来越多，需要的交换机也越来越多

**路由器**是基于 IP 设计的，俗称**三层**网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；

但是交换机的**容量和性能有限**，MAC 地址表无法记录全世界电脑的 MAC 地址和对应的端口号，MAC 地址表太大也无法快速查找到对应的 MAC 地址表项

于是就有了三层网络设备**路由器**，路由器可以把全世界的网络连接起来

**局域网内的网络连接可以使用交换机，例如一个公司内的网络或者一个校园内的网络通过交换机连接**

**不同区域的局域网互联使用路由器**

:apple: **路由器是数据通向互联的大门**

**:banana: 路由器基本原理:**

路由器的端口**具有 MAC 地址**，因此它就**能够成为以太网的发送方和接收方**；同时还**具有 IP 地址**，从这个意义上来说，它和计算机的网卡是一样的，可以将路由器看作一个轻量级的主机。**一台路由器中有多个输出端口，每个端口有一个IP地址。**

当转发包时，首先路由器端口会接收发给自己的以太网包，然后**路由表**查询转发目标，再由相应的端口作为发送方将以太网包发送出去。

路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/24.jpg" alt="路由器转发" style="zoom: 60%;" />

在网络包传输的过程中，**源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址**，因为需要 MAC 地址在以太网内进行**两个设备**之间的包传输。

## 4.网络分类

**I.个域网PAN（ Personal Area Network ）:**

能在便携式消费电器与通信设备之间进行短距离通信的网络，覆盖范围一般在10米半径以内，如蓝牙耳机等

**II.局域网LAN（Local Area Network）：**

- 局部地区形成的区域网络，如企业网络
- 分布地区范围有限，可大可小，大到一栋建筑、小到办公室内的组网
- 电脑WLAN接入，打印机共享等等

**III.城域网MAN（Metropolitan Area Network ）：**

范围覆盖一个城市的网络

**IV.广域网WAN（Wide Area Network）：**

覆盖很大地理区域，乃至覆盖地区和国家

# 二、应用层：

## 1、常见的应用层协议有哪些？

### I.HTTP协议：

**超文本传输协议（HTTP，HyperText Transfer Protocol)** 主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。**HTTP 协是基于 TCP协议**，目前使用的 HTTP 协议大部分都是 1.1。在 1.1 的协议里面，**默认是开启了 Keep-Alive 的，这样的话建立的连接就可以在多次请求中被复用了。**另外， **HTTP 协议是”无状态”的协议，它无法记录客户端用户的状态**，一般我们都是通过 Session 来记录客户端用户的状态

### II.SMTP:简单邮件传输(发送)协议

**简单邮件传输(发送)协议（SMTP，Simple Mail Transfer Protocol）** **基于 TCP 协议**，用来发送电子邮件。

:exclamation:**接受邮件的协议不是 SMTP 而是 POP3 协议。SMTP只负责邮件的发送**

:hamburger:**电子邮件的发送过程？**

比如我的邮箱是“csg@163.com”，我要向“daisi@qq.com”发送邮件，整个过程可以简单分为下面几步：

1. 通过 **SMTP** 协议，我将我写好的邮件交给163邮箱服务器（邮局）。
2. 163邮箱服务器发现我发送的邮箱是qq邮箱，然后它使用 SMTP协议将我的邮件转发到 qq邮箱服务器。
3. qq邮箱服务器接收邮件之后就通知邮箱为“daisi@qq.com”的用户来收邮件，然后用户就通过 **POP3/IMAP** 协议将邮件取出。

**:santa:SMTP的作用：**

- SMTP用来将邮件从发送方的用户代理（用户本身）传送到发送方的邮件服务器

- SMTP用来将邮件从发送方的邮件服务器传输到接收方的邮件服务器

接收方代理即客户端，用户真正收到邮件的终端。而接收方服务器只是一个保存邮件的中转站。

### III.POP3/IMAP:邮件接收的协议

这两个协议没必要多做阐述，只需要了解 **POP3 和 IMAP 两者都是负责邮件接收的协议**即可。另外，需要注意不要将这两者和 SMTP 协议搞混淆了。**SMTP 协议只负责邮件的发送，真正负责接收的协议是POP3/IMAP。**

IMAP 协议相比于POP3更新一点，为用户提供的可选功能也更多一点,几乎所有现代电子邮件客户端和服务器都支持IMAP。大部分网络邮件服务提供商都支持POP3和IMAP。

### IV.FTP:文件传输协议

**FTP 协议** 主要提供文件传输服务。使用 FTP 传输文件的好处是可以屏蔽操作系统和文件存储方式。

FTP 是基于客户—服务器（C/S）模型而设计的，在客户端与 FTP 服务器之间建立两个连接。如果我们要基于 FTP 协议开发一个文件传输的软件的话，首先需要搞清楚 FTP 的原理。关于 FTP 的原理，很多书籍上已经描述的非常详细了：

### V.Telnet:远程登陆协议

**Telnet 协议** 通过一个终端登陆到其他服务器，建立在可靠的传输协议 **TCP 之上**。Telnet 协议的最大缺点之一是所有数据（包括用户名和密码）均**以明文形式发送，这有潜在的安全风险。**这就是为什么如今很少使用Telnet并被一种称为SSH的非常安全的协议所取代的主要原因。

### VI.SSH:安全的网络传输协议

**SSH（ Secure Shell）** 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。**SSH 建立在可靠的传输协议 TCP 之上。**

**Telnet 和 SSH 之间的主要区别在于 SSH 协议会对传输的数据进行加密保证数据安全性。**

### VII.DNS协议

:rabbit:**DNS(Domain Name System)是：**

- 一个由分层的DNS服务器（DNS Server）实现的分布式数据库；
- 一个使主机能够查询分布式数据库的应用层协议；
- DNS服务器通是运行BIND软件的UNIX机器；
- DNS运行在UDP上，使用53端口

我们在上网的时候，通常使用的方式是域名，而不是 IP 地址，因为域名方便人类记忆。那么实现这一技术的就是 **DNS 域名解析**，DNS 可以将域名网址自动转换为具体的 IP 地址。

:package:**域名的层级关系：**

DNS 中的域名都是用**句点**来分隔的，比如 `www.server.com`，这里的句点代表了不同层次之间的**界限**。

在域名中，**越靠右**的位置表示其层级**越高**。

- 根 DNS 服务器
- 顶级域 DNS 服务器（com）
- 权威 DNS 服务器（server.com）

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/32.jpg" alt="DNS 树状结构" style="zoom:67%;" />

:game_die: **域名解析的工作流程**

浏览器首先看一下自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件 `hosts`，如果还是没有，就会 DNS 服务器进行查询，查询的过程如下：

**从根域名递归向下查找直到找到域名对应的IP地址**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/33.jpg" alt="域名解析的工作流程" style="zoom:50%;" />

## 2.HTTP的常见状态码有哪些？

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" alt=" 五大类 HTTP 状态码 " style="zoom:50%;" />

:dagger: `1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

:dancer: `2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

:sailboat: `3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

- 「**301 Moved Permanently**」表示**永久重定向**，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
- 「**302 Found**」表示**临时重定向**，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

- 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以**继续使用缓存资源，用于缓存控制。**

:face_with_thermometer: `4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

:baby: `5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

- 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。

## 3.URI和URL的区别与联系

**URI** ：统一资源标志符(Uniform Resource Identifier， URI)，表示的是web上每一种可用的资源，如 HTML文档、图像、视频片段、程序等都由一个URI进行标识的。

URI一般由三部组成：
①访问资源的命名机制
②存放资源的主机名
③资源自身的名称，由路径表示，着重强调于资源。

**URL** ： Universal Resource Locator 统一资源定位符

①协议(或称为服务方式)
②存有该资源的主机IP地址(有时也包括端口号)
③主机资源的具体地址。如目录和文件名等。

例如：http:*//root@localhost:8080/appname/path?name=errol&password=123#segment*

**URN** ： Universal Resource Name 统一资源名称，通过特定命名空间中的唯一名称或ID来标识资源。

URI和URL都定义了资源是什么，但URL还定义了该如何访问资源。URL是一种具体的URI，它是URI的一个子集，它不仅唯一标识资源，而且还提供了定位该资源的信息。URI 是一种语义上的抽象概念，可以是绝对的，也可以是相对的，而URL则必须提供足够的信息来定位，是绝对的。

**只要能唯一标识资源的就是URI，在URI的基础上给出其资源的访问方式的就是URL**。

## 4、HTTP常见字段

- *Host* 字段

```text
Host: www.A.com
```

有了 `Host` 字段，就可以将请求发往「同一台」服务器上的不同网站。

- *Content-Length 字段*

服务器在返回数据时，会有 `Content-Length` 字段，表明本次回应的数据长度。

```text
Content-Length: 1000
```

**HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题**。

- *Connection 字段*

`Connection` 字段最常用于客户端要求服务器使用「 HTTP 长连接」机制，以便其他请求复用。

```text
Connection: Keep-Alive
```

开启了 HTTP Keep-Alive 机制后， 连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个连接，一直持续到客户端或服务器端提出断开连接。

- *Content-Type 字段*

`Content-Type` 字段用于服务器回应时，告诉客户端，本次数据是什么格式。

```text
Content-Type: text/html; charset=utf-8
```

上面的类型表明，发送的是网页，而且编码是UTF-8。

客户端请求的时候，可以使用 `Accept` 字段声明自己可以接受哪些数据格式。

```text
Accept: */*
```

上面代码中，客户端声明自己可以接受任何格式的数据。

- *Content-Encoding 字段*

`Content-Encoding` 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式

```text
Content-Encoding: gzip
```

上面表示服务器返回的数据采用了 gzip 方式压缩，告知客户端需要用此方式解压。

客户端在请求时，用 `Accept-Encoding` 字段说明自己可以接受哪些压缩方法。

```text
Accept-Encoding: gzip, deflate
```

## 5.HTTP常见请求方式

1. get：向服务端获取资源，所以查询操作一般用get
2. post：向服务端提交**请求字段**，创建操作使用 post，该操作**不是幂等的，多次执行会导致多条数据被创建**
3. put：**修改指定URL的资源**，如果资源不存在，则进行创建，修改操作一般使用 put，在http中，**put 被定义成幂等的，多次操作会导致前面的数据被覆盖**
4. patch：局部修改URL所在资源的数据，是对put的补充
5. delete：删除指定URL的资源。
6. head：获取响应报文的首部，即获得URL资源的头部
7. options：询问服务器支持哪些方法，响应头中返回 Allow: GET、POST、HEAD
8. trace：追踪路径，主要用于测试或诊断；在请求头中在Max-Forwards字段设置数字，每经过一个服务器该数字就减一，当到0的时候就直接返回，一般通过该方法检查请求发送出去是否被篡改

## 6.GET和POST的区别

1. 功能：GET一般用来从服务器上面获取资源，POST一般用来更新服务器上面的资源。
2. 幂等性：GET是幂等的，POST为非幂等的
3. 安全性：GET请求的参数会明文附加在URL之后，而 POST请求提交的数据则**被封装到请求体中**，相对更安全。
4. 传输数据量的大小：GET请求允许发送的数据量比较小，大多数浏览器都会限制请求的url长度在2048个字节，而大多数服务器最多处理64K大小的url；而POST请求提交的数据量则是没有大小限制的。
5. 参数的数据类型：GET只接受ASCII字符，而POST没有限制。
6. GET在浏览器回退时是无害的，而POST会再次提交请求。
7. GET请求可以被缓存，可以被保留在浏览器的历史记录中；POST请求不会被缓存，不会被保留在浏览器的历史记录中。

## 7.HTTP报文分析

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xODU2NDE5LWY4YjU2MDMxYmNjNjhmZjgucG5n" alt="查看源图像" style="zoom:67%;" />

<img src="http://cdn.tobebetterjavaer.com/tobebetterjavaer/images/cs/wangluo-58884113-14dc-4cca-a63e-3320f31a4da5.png" alt="img" style="zoom: 80%;" />

### 1）报文类型：报文类型分为请求报文和响应报文

> ① 请求报文包含三部分：
>
> - 请求行：包含请求方法、URI、HTTP版本信息
> - 请求头：(key value形式)，比如content-type，content-length等
> - 请求体：请求实体，比如post请求提交表单时可以是一个json对象
>
> ② 响应报文包含三部分：
>
> - 状态行：包含HTTP版本、状态码、状态码的原因短语
> - 响应头
> - 响应体

### （2）报文中各部分的简要描述：

- 方法(method)：客户端希望服务器对资源执行的动作，是一个单独的词，比如：get 或者 post

- 请求URL(request-URL)：请求URL是资源的绝对路径，服务器可以假定自己是URL的主机/端口
- 版本(version)：报文所使用的Http版本，其格式：HTTP/<主要版本号>.<次要版本号>
- 状态码(status-code)：标识请求过程中所发生的情况
- 原因短语(reason-phrase)：数字状态码的可读版本，包含行终止序列之前的所有文本。
- 请求头部(header)：可以有零个或多个头部，每个首部都包含一个名字，后面跟着一个冒号(:)，然后是一个可选的空格，接着是一个值，最后是一个CRLF首部是由一个空行(CRLF)结束的，表示了头部列表的结束和实体主体部分的开始
- 实体的主体部分(entity-body)：实体的主体部分包含一个由任意数据组成的数据块，并不是所有的报文都包含实体的主体部分，有时，报文只是以一个CRLF结束。

### （3）通用头部：

**既可以出现在请求报文中，也可以出现在响应报文中，它提供了与报文相关的最基本的信息：**

- Connection：允许客户端和服务器指定与请求/响应连接有关的选项，http1.1之后默认是 keep-alive

- Date：日期和时间标志，说明报文是什么时间创建的
- Transfer-Encoding：告知接收端为了保证报文的可靠传输，对报文采用了什么编码方式
- Cache-Control：用于随报文传送缓存指示

### （4）请求头部：

**请求头部是只在请求报文中有意义的头部。用于说明是谁或什么在发送请求、请求源自何处，或者客户端的喜好及能力**

- Host：给出了接收请求的服务器的主机名和端口号

- Referer：提供了包含当前请求URI的文档的URL
- User-Agent：将发起请求的应用程序名称告知服务器
- Accept：告诉服务器能够发送哪些媒体类型
- Accept-Encoding：告诉服务器能够发送哪些编码方式
- Accept-Language：告诉服务器能够发送哪些语言
- Range：如果服务器支持范围请求，就请求资源的指定范围
- If-Range：允许对文档的某个范围进行条件请求
- Authorization：包含了客户端提供给服务器，以便对其自身进行认证的数据
- Cookie：客户端用它向服务器传送数据

### （5）响应头部：

**响应头部为客户端提供了一些额外信息，比如谁在发送响应、响应者的功能，甚至与响应相关的一些特殊指令**

- Age：(从最初创建开始)响应持续时间

- Server：服务器应用程序软件的名称和版本
- Accept-Ranges：对此资源来说，服务器可接受的范围类型
- Set-Cookie：在客户端设置数据，以便服务器对客户端进行标识

### （6）实体首部：

**描述主体的长度和内容，或者资源自身**

- Allow：列出了可以对此实体执行的请求方法
- Location：告知客户端实体实际上位于何处，用于将接收端定向到资源的位置(URL)上去
- Content-Base：解析主体中的相对URL时使用的基础URL
- Content-Encoding：对主体执行的任意编码方式
- Content-Language：理解主体时最适宜使用的自然语言
- Content-Length：主体的长度
- Content-Type：这个主体的对象类型
- ETag：与此实体相关的实体标记
- Last-Modified：这个实体最后一次被修改的日期和时间

### （7）实体的主体部分：

**该部分其实就是HTTP要传输的内容，是可选的。HTTP报文可以承载很多类型的数字数据**，比如，JSON对象，图片、视频、HTML文档电子邮件、软件应用程序等等。

## 8.HTTP缓存技术

### I.什么是缓存？

- 缓存是指代理服务器或客户端本地磁盘内保存的资源副本。利用缓存可减少对源服务器的访问，因此节省了通信时间。
- 缓存服务器的优势在于利用缓存可以避免多次从源服务器转发资源
- 客户端缓存被称为临时网络文件。浏览器缓存如果有效，就不必再向服务器请求相同的资源了，可以直接从本地读取。

### II.HTTP请求了两种缓存方式

#### :game_die:**强制缓存：**

强缓存指的是**只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存**，决定是否使用缓存的主动性在于浏览器这边。

如下图中，返回的是 200 状态码，但在 200后面标识的是 `来自内存换粗`，就是使用了强制缓存。

![image-20221025161407931](C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221025161407931.png)

缓存是利用下面这**两个 HTTP 响应头部（Response Header）字段**实现的，它们都用来表示资源在客户端缓存的有效期：

- `Cache-Control`， 是一个相对时间；
- `Expires`，是一个绝对时间；

如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，**Cache-Control的优先级高于 Expires** 。

Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；
- 浏览器再次请求访问服务器中的该资源时，会先**通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，如果没有，则使用该缓存，否则重新请求服务器；
- 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。

#### :facepunch:协商缓存：

当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的**响应码是 `304`，这个是告诉浏览器可以使用本地缓存的资源**，通常这种通过**服务端告知客户端是否可以使用缓存的方式被称为协商缓存**。

**协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/http%E7%BC%93%E5%AD%98.png" alt="img" style="zoom:50%;" />

**协商缓存这两个字段都需要配合强制缓存中 Cache-control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求**。

## 9、Cookie和Session的区别

### **I.Cookie和Session介绍：**

Session：当客户端第一次访问服务器时，服务器会为该客户端创建一个Session对象，该Session对象记录了客户端的登录状态，制止连接断开。之后在服务器返回的响应体中有一个Set-Cookie字段，该字段就是JSESSIONEID，即客户端Session的唯一标识。

Cookie：Cookie本质上就是客户端Session的id,当客户端收到服务器响应后，浏览器会将Cookie保存在本地，当再次访问服务器时，会带上Cookie字段，服务器会根据Cookie（JSESSIONID）来检验登录状态，如果未过期或断开，则不需要重新建立连接。

### II.Cookie和Session的区别：

- 保存位置与安全性：cookie保存在客户端，session保存在服务端，所以在安全性上面，cookie存在安全隐患，可以通过拦截或本地文件找到cookie后进行攻击，而session相对更加安全。因此，可以将登陆信息等重要信息存放为session中；其他信息如果需要保留，可以放在cookie中。
- 存储容量：单个cookie最大只允许4KB，一个站点最多保存20个Cookie；session没有大小限制，个数只跟服务器的内存大小有关。
- 有效期与实现机制：cookie可长期有效存在；session依赖于cookie，过期时间默认为-1，只需关闭窗口该 session 就会失效。每个客户端对应一个session ，客户端之间的 session  相互独立；

### III.什么是Token

Token是由服务器收到客户端发送来的用户名，密码等信息后为保存用户状态而根据加密算法生成的一串字符口令，它会在第一次相应客户端后返回给客户端保留，服务器并不对token进行保存，只会在客户端再次访问浏览器时根据密钥解密token而验证用户身份。

基于Token的身份验证的过程如下:

1. 用户通过用户名和密码发送请求。
2. 程序验证。
3. 程序返回一个签名的token 给客户端。
4. 客户端储存token,并且每次用于每次发送请求。
5. 服务端验证token并返回数据。

#### Token的优势

- **无状态、可扩展**

在客户端存储的Tokens是无状态的，并且能够被扩展。基于这种无状态和不存储Session信息，负载负载均衡器能够将用户信息从一个服务传到其他服务器上。

如果我们将已验证的用户的信息保存在Session中，则每次请求都需要用户向已验证的服务器发送验证信息(称为Session亲和性)。用户量大时，可能会造成一些拥堵。

但是不要着急。使用tokens之后这些问题都迎刃而解，因为tokens自己hold住了用户的验证信息。

- **安全性**

请求中发送token而不再是发送cookie能够防止CSRF(跨站请求伪造)。即使在客户端使用cookie存储token，cookie也仅仅是一个存储机制而不是用于认证。不将信息存储在Session中，让我们少了对session操作。

token是有时效的，一段时间之后用户需要重新验证。我们也不一定需要等到token自动失效，token有撤回的操作，通过token revocataion可以使一个特定的token或是一组有相同认证的token无效。

- **可扩展性**

Tokens能够创建与其它程序共享权限的程序。例如，能将一个随便的社交帐号和自己的大号(Fackbook或是Twitter)联系起来。当通过服务登录Twitter(我们将这个过程Buffer)时，我们可以将这些Buffer附到Twitter的数据流上(we are allowing Buffer to post to our Twitter stream)。

使用tokens时，可以提供可选的权限给第三方应用程序。当用户想让另一个应用程序访问它们的数据，我们可以通过建立自己的API，得出特殊权限的tokens。

- **多平台跨域**

我们提前先来谈论一下CORS(跨域资源共享)，对应用程序和服务进行扩展的时候，需要介入各种各种的设备和应用程序。

只要用户有一个通过了验证的token，数据和资源就能够在任何域上被请求到。

Access-Control-Allow-Origin: *      

## 10.HTTP进化史

### I.HTTP/1.1的优点与缺点？

**:factory:优点：**

*1. 简单*

HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**。

*2. 灵活和易于扩展*

HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**。

同时 HTTP 由于是工作在应用层（ `OSI` 第七层），则它**下层可以随意变化**，比如：

- HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层；
- HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。

*3. 应用广泛和跨平台*

互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有**跨平台**的优越性

:package:**缺点**：

*1. 无状态*

无状态的**好处**，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。

无状态的**坏处**，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦，例如购物下单。

对于无状态的问题，解法方案有很多种，其中比较简单的方式用 **Cookie** 技术。

`Cookie` 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。

*2. 明文传输*

明文意味着在传输过程中的信息，是可方便阅读的，比如 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。

但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于**信息裸奔**。

*3. 不安全*

HTTP 比较严重的缺点就是不安全：

- 通信使用明文（不加密），内容可能会被窃听。比如，**账号信息容易泄漏，那你号没了。**
- 不验证通信方的身份，因此有可能遭遇伪装。比如，**访问假的淘宝、拼多多，那你钱没了。**
- 无法证明报文的完整性，所以有可能已遭篡改。比如，**网页上植入垃圾广告，视觉污染，眼没了。**

HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。

### II. HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

HTTP/1.1 相比 HTTP/1.0 性能上的改进：

1. **连接方式** : HTTP 1.0 为短连接，HTTP 1.1 支持长连接。
2. **状态响应码** : HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，`100 (Continue)`——在请求大资源前的预热请求，`206 (Partial Content)`——范围请求的标识码，`409 (Conflict)`——请求与当前资源的规定冲突，`410 (Gone)`——资源已被永久转移，而且没有任何已知的转发地址。
3. **缓存处理** : 在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified`未修改`-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。
4. **带宽优化及网络连接的使用** :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
5. **Host头处理** : HTTP/1.1在请求头中加入了`Host`字段。
6. **支持管道**（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间,**解决请求队头阻塞问题。**

但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）**未经压缩就发送**，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- 发送**冗长的首部。**每次互相发送相同的首部造成的浪费较多；
- 服务器是按**请求的顺序响应的**，如果服务器响应慢，会导致客户端一直请求不到数据，也就是**队头阻塞；**
- **没有请求优先级控制**；
- **请求只能从客户端开始，服务器只能被动响应**。

### III.HTTPS详解

#### :v: HTTP和HTTPS的区别：

HTTP 是明文传输协议，HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全

- HTTPS比HTTP更加安全，对搜索引擎更友好，利于SEO，谷歌、百度优先索引HTTPS网页
- HTTPS需要用到SSL证书，而HTTP不用
- HTTPS标准端口443，HTTP标准端口80
- HTTPS基于传输层，HTTP基于应用层
- HTTPS在浏览器显示绿色安全锁，HTTP没有显示

#### :ghost:HTTP存在的问题：

- **窃听风险**，比如通信链路上可以获取通信内容，盗号。
- **篡改风险**，比如强制植入垃圾广告，视觉污染。
- **伪装风险**，比如冒充淘宝网站，用户钱容易没，盗版网站。

#### :jack_o_lantern:HTTPS是如何解决HTTP的问题的？

​																**HTTP + 加密 + 认证 + 完整性保护 = HTTPS**

------

**加密方式**：HTTPS的加密方式为**混合加密**，即 **对称加密（共享密钥加密） + 非对称加密（公开密钥加密）**

  **单独使用对称加密和非对称加密存在的问题**：

- **对称加密：**加密和解密用**同一个密钥（共享密钥）的方式称为对称密钥加密**，以**对称密钥加密时必须要将密钥传输给对方**，如果在传输过程中密钥被窃取，这时中间人就可以进行解密，这样加密也就失去了意义。
- **非对称加密：**非对称加密使用一对非对称密钥，一把是**公开密钥**，一把是**私有密钥**，公钥可以随便发布，**发送报文的一方使用对方的公钥进行加密**，发送后，接收方使用自己的私钥进行解密，这样就可实现报文不可被窃取。但这样的加密方式同样存在问题，如果中间人获取了接收方的公钥，这时中间人可伪装成真正的发送方与接收方通信。

***1. 混合加密（解决窃听问题）***

通过**混合加密**的方式可以保证信息的**机密性**，解决了窃听的风险。

- 在通信建立前采用**非对称加密**的方式交换「共享秘钥」，后续就不再使用非对称加密。
- 在通信过程中全部使用**对称加密**的「共享秘钥」的方式加密明文数据，由于通信建立前已经交换了共享密钥（双方都已经持有），所以在通信时就不用再传输共享密钥了。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/20-%E6%B7%B7%E5%90%88%E5%8A%A0%E5%AF%86.png" alt="混合加密" style="zoom: 80%;" />

这样就可保证信息的**机密性**，解决了**窃听的风险**。

采用「混合加密」的方式的原因：

- **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
- **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

***2. 摘要算法 + 数字签名***

虽然信息的机密性可以保证了，中间人虽然无法获取信息内容，但仍然可以**对加密后的信息进行篡改**，所以我们要用摘要算法 + 数字签名来解决这一问题。

在计算机里会**用摘要算法（哈希函数）来计算出发送的内容的哈希值**，也就是内容的「指纹」，这个**哈希值是唯一的，且无法通过哈希值推导出内容**。只有当接收方计算出了内容的哈希值B并且和发送方发来的哈希值A相匹配，才可任务数据是完成且未被篡改的。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E6%91%98%E8%A6%81%E7%AE%97%E6%B3%95.png" alt="img" style="zoom:50%;" />

通过哈希算法可以确保内容不会被篡改，**但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明**。

那为了避免这种情况，计算机里会用**非对称加密算法**来解决，共有两个密钥：

- 一个是公钥，这个是可以公开给所有人的；
- 一个是私钥，这个必须由本人管理，不可泄露。

非对称加密的用途主要在于**通过「私钥加密，公钥解密」的方式，来确认消息的身份**，我们常说的**数字签名算法**，就是用的是这种方式，不过私钥加密内容不是内容本身，而是**对内容的哈希值加密**。即服务端用**私钥**对自己发送的内容哈希值A加密，客户端接收到后不但要计算哈希值B，还要用公钥解密哈希值A，然后再做比较。由于哈希值A是由服务器的私钥加密，所以如果中间人替换后，客户端的公钥是无法解密的，从而也就可以避免内容和哈希值被替换。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D.png" alt="img" style="zoom:50%;" />

***3. 数字证书***

到目前，窃听风险和篡改风险都已经被解决了，但**伪装风险**任然存在，由于公开密钥是要由服务端在网络上传输给客户端的，所以**公开密钥在途中就有被替换的风险**，这时就需要一个中间人来对公开密钥的身份进行合法性担保。

在计算机里，这个权威的机构就是 CA （**数字证书认证机构**），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/22-%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="数子证书工作流程" style="zoom:75%;" />

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E7%9A%84%E6%A0%A1%E9%AA%8C.png" alt="img" style="zoom:50%;" />

CA 签发证书的过程，如上图左边部分：

- 首先 CA 会把持有者**（服务器）的公钥、用途、颁发者、有效时间等信息打成一个包**，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
- 然后 CA 会使用自己的私钥将该 **Hash 值加密**，生成 **Certificate Signature**，也就是 CA 对证书做了**签名**；
- 最后将 Certificate Signature 添加在文件证书上，形成数字证书；

客户端校验服务端的数字证书的过程，如上图右边部分：

- 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
- 最后比较 H1 和 H2，如果值相同，则为可信赖的证书（即该公钥正是服务器的公钥），否则则认为证书不可信（即公钥是伪造的）。

**小总结：**

CA是客户端和服务端的一个可靠中间人，它会将自己的公钥事先植入到客户端操作系统中，如果一个服务器要开通HTTPS服务，它需事先把服务器自己的公钥向CA注册，CA用自己的私钥为服务器的公钥生成数字证书（可理解为加密后的服务器公钥），当服务器与客户端建立连接时，就会把该数字证书发给客户端，客户端用CA事先植入的公钥对数字证书进行验证，如果合法就可得到服务器的公钥，之后服务器与客户端在TSL第三次握手时就会使用到该公钥。

:label:**证书的信任链问题**：

我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/baidu%E8%AF%81%E4%B9%A6.png)

**操作系统里一般都会内置一些根证书**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%94%A8%E6%88%B7%E4%BF%A1%E4%BB%BB.png" alt="img" style="zoom:50%;" />

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E9%93%BE.png" alt="img" style="zoom:50%;" />

最后一个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，而是要搞那么多中间层级呢？

**这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。**

#### :ice_cream:HTTPS是如何建立连接的？

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/19-HTTPS%E4%B8%8EHTTP.png" alt="img" style="zoom:67%;" />

有了 TLS 协议，能保证 HTTP 通信是安全的了，那么在**进行 HTTP 通信前，需要先进行 TLS 握手。**通常经过「四个消息」就可以完成 TLS 握手，也就是需要 2个 RTT 的时延，然后就可以在安全的通信环境里发送 HTTP 报文，实现 HTTPS 协议。

***1. ClientHello***

首先，由客户端向服务器发起加密通信请求，也就是 `ClientHello` 请求。

在这一步，客户端主要向服务器发送以下信息：

（1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。

（2）客户端生产的随机数（`Client Random`），后面用于生成「会话秘钥」条件之一。

（3）客户端支持的密码套件列表，如 RSA 加密算法。

***2. SeverHello***

服务器收到客户端请求后，向客户端发出响应，也就是 `SeverHello`。服务器回应的内容有如下内容：

（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。

（2）服务器生产的随机数（`Server Random`），也是后面用于生产「会话秘钥」条件之一。

（3）确认的密码套件列表，如 RSA 加密算法。

（4）服务器的数字证书。

***3.客户端回应***

客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

如果证书没有问题，客户端会**从数字证书中取出服务器的公钥**，然后使用它加密pre-master key，向服务器发送如下信息：

（1）一个随机数（`pre-master key`）。该随机数会被服务器公钥加密。

（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。

（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。

上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。

**服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」**。

***4. 服务器的最后回应***

服务器收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。

然后，向客户端发送最后的信息：

（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。

（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。

至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。

![HTTPS 连接建立过程](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/23-HTTPS%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

#### :sailboat: HTTPS一定可靠吗？

中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己伪造的证书给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/%E8%AF%81%E4%B9%A6%E5%AE%89%E5%85%A8%E6%8F%90%E7%A4%BA.png)

HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，**本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书）**，并不是 HTTPS 不够安全。

#### :lantern: 如何避免被中间人抓取数据？

我们要保证自己电脑的安全，不要被病毒乘虚而入，而且也不要点击任何证书非法的网站，这样 HTTPS 数据就不会被中间人截取到了。

当然，我们还可以通过 **HTTPS 双向认证**来避免这种问题。

一般我们的 HTTPS 是单向认证，客户端只会验证了服务端的身份，但是服务端并不会验证客户端的身份。

如果用了双向认证方式，**不仅客户端会验证服务端的身份，而且服务端也会验证客户端的身份。**服务端一旦验证到请求自己的客户端为不可信任的，服务端就拒绝继续通信，客户端如果发现服务端为不可信任的，那么也中止通信。

### IV.HTTP/2 做了什么优化？

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/25-HTTP2.png" alt="HTT/1 ~ HTTP/2" style="zoom:67%;" />

HTTP/2 相比 HTTP/1.1 性能上的改进：

- 头部压缩
- 二进制格式
- 并发传输
- 服务器主动推送资源

***1. 头部压缩***

**HTTP 1.x首部是没有压缩的，Gzip只会对请求体进行压缩**，现在HTTP 2.0 提供了首部压缩方案。现在SPDY和HTTP 2.0都支持首部压缩，前者使用的是DEFLATE算法，而后者使用专门设计的HPACK算法。

HTTP/2 会**压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的部分**。

这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。

***2. 二进制格式***

HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式**，头信息和数据体都是二进制，并且统称为帧（frame）：**头信息帧（Headers Frame）和数据帧（Data Frame）**。

这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这**增加了数据传输的效率**。

***3. 并发传输***

我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了**队头阻塞**的问题。

HTTP/2，引出了 Stream 概念，**多个 Stream 复用在一条 TCP 连接。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http2/stream.png" alt="img" style="zoom:67%;" />

我们可以得出个结论：**多个 Stream 跑在一条 TCP 连接，同一个 HTTP 请求与响应是跑在同一个 Stream 中，HTTP 消息可以由多个 Frame 构成， 一个 Frame 可以由多个 TCP 报文构成。**

***4. 服务器主动推送***

一般HTTP请求都是由客户端发起，服务器收到请求进行返回。但是HTTP 2.0 可以使**服务器主动返回资源**给客户端用户。比如**前端请求 /index.html 资源，但服务器把 /index.css ， index.png 都返回了，这样就可以提高了性能。**

客户端和服务器**双方都可以建立 Stream**，因为服务端可以主动推送资源给客户端， 客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。

比如下图，Stream 1 是客户端向服务端请求的资源，属于客户端建立的 Stream，所以该 Stream 的 ID 是奇数（数字1）；Stream 2 和 4 都是服务端主动向客户端推送的资源，属于服务端建立的 Stream，所以这两个 Stream 的 ID 是偶数（数字 2 和4）。

<img src="https://img-blog.csdnimg.cn/83445581dafe409d8cfd2c573b2781ac.png" alt="img" style="zoom:50%;" />

在 Nginx 中，可以通过 `http2_max_concurrent_Streams` 配置来设置 Stream 的上限，默认是 128 个。

HTTP/2 通过 Stream 实现的并发，比 HTTP/1.1 通过 TCP 连接实现并发要牛逼的多，**因为当 HTTP/2 实现 100 个`并发` Stream 时，只需要建立一次 TCP 连接，而 HTTP/1.1 需要建立 100 个 TCP 连接，每个 TCP 连接都要经过TCP 握手、慢启动以及 TLS 握手过程，这些都是很耗时的。** *(HTTP/1.1中所谓的长连接之针对于串行执行的HTTP请求，如果是并发的请求就要建立多个TCP连接)*

#### :dancer: HTTP/2 有什么缺陷？

 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是**在 TCP 这一层。**

**HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/http2%E9%98%BB%E5%A1%9E.jpeg" alt="img" style="zoom:67%;" />

举个例子，如下图：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http3/tcp%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E.gif" alt="img" style="zoom: 80%;" />

图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号**，其中 packet 3 在网络中丢失了，即使 packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层面发生的。**

:gem:**所以，一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。**

### V.HTTP/3做了哪些优化？

- TTP/1.1 中的管道（ pipeline）虽然解决了**请求的队头阻塞**，但是**没有解决响应的队头阻塞**，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，**这属于 HTTP 层队头阻塞。**
- HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是**一旦发生丢包，就会阻塞住所有的 HTTP 请求**，这属于 **TCP 层队头阻塞。**

HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/27-HTTP3.png" alt="HTTP/1 ~ HTTP/3" style="zoom:67%;" />

UDP 发送是**不管顺序，也不管丢包的**，所以不会出现像 HTTP/2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。

QUIC 有以下 3 个特点。

- 无队头阻塞
- 更快的连接建立
- 连接迁移

#### :v: 无队头阻塞

QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。

由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心。

不过 QUIC 协议会保证数据包的可靠性，**每个数据包都有一个序号唯一标识。**当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。

**QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响，这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。**

#### :sunflower: 更快的连接建立

QUIC 内部包含 TLS1.3，因此仅需 **1 个 RTT 就可以「同时」完成建立连接与 TLS 密钥协商**，甚至在**第二次连接的时候**，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，**达到 0-RTT 的效果。**

#### :camel: 连接迁移

基于 TCP 传输协议的 HTTP 协议，由于是通过**四元组**（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。**QUIC的连接不需要该四元组的支持。**

那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 **IP 地址变化了，那么就必须要断开连接，然后重新建立连接**，而建立连接的过程包含 **TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程**，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，**只要仍保有上下文信息（比如连接 ID、TLS 密钥等）**，就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

### VI.说一说WebSocket

- TCP 协议本身是**全双工**的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是**半双工**的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。
- 在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用**定时轮询或者长轮询**的方式实现**服务器推送**(comet)的效果。
- 对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 **WebSocket 协议,通过WebSocket可实现全双工通信**。
- WebSocket 和 socket 几乎没有任何关系，只是叫法相似。
- 正因为各个浏览器都支持 HTTP协 议，所以 **WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作**，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。

```apl
HTTP/1.1 101 Switching Protocols\r\n
Sec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\r\n
Upgrade: WebSocket\r\n #TCP握手结束后升级为websocket
Connection: Upgrade\r\n
```

# 三、传输层

## 1.TCP基础

### :headphones: TCP概念及特点

TCP是一个传输层协议，提供可靠传输，支持全双工，是一个连接导向的协议。

**双工/单工**

在任何一个时刻，如果数据只能单向发送，就是单工。

如果在某个时刻数据可以向一个方向传输，也可以向另一个方向反方向传输，而且交替进行，叫作半双工；半双工需要至少 1 条线路。

如果任何时刻数据都可以双向收发，这就是全双工，全双工需要大于 1 条线路。

**TCP协议的主要特点**

- TCP是**面向连接**的运输层协议；所谓面向连接就是双方传输数据之前，必须先建立一条通道，例如三次握手就是建议通道的一个过程，而四次挥手则是结束销毁通道的一个其中过程。
- TCP提供**可靠的传输服务**。传送的数据无差错、不丢失、不重复、按序到达；
- TCP提供**全双工通信**。允许通信双方的应用进程在任何时候都可以发送数据，因为两端都设有发送缓存和接受缓存；
- **面向字节流**。虽然应用程序与TCP交互是一次一个大小不等的数据块，但TCP把这些数据看成一连串无结构的字节流。消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。
- **不保证接收方收到的数据块和发送方发送的数据块具有对应大小关系**，这也就是会发生半包黏包的原因。

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzguanBn?x-oss-process=image/format,png" alt="img" style="zoom:67%;" />

### :gemini: TCP 头格式(大小为20~60B)

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzYuanBn?x-oss-process=image/format,png" alt="TCP 头格式" style="zoom: 60%;" />

**:selfie: 序列号(Seq)**：**报文段首字节的字节流编号**（一个报文段由若干字节组成,MSS为最大报文段长度，多个报文段组成数据流）。在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**

**:bacon: 确认应答号**：指下一次「期望」收到的数据的序列号（Seq），发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

- 主机A填充进报文段的确认号是主机A期望从主机B收到的下一字节的序号。
- Seq（我发送的） = ACK（上一次对方发来的）
- ACK（我本次发送的） = Seq（对方上一次发来的） + 1

**控制位：**

- *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
- *RST*：该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。
- *SYN*：该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
- *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段。

### :family:什么是TCP连接？

一个TCP由一个**四元组**确定，只要不满足其一，就非同一连接 ：

- 源地址
- 源端口
- 目的地址
- 目的端口

**源地址和目的地址的字段（32位）是在 IP 头部中**，作用是通过 IP 协议发送报文给**对方主机**。

**源端口和目的端口的字段（16位）是在 TCP 头部中**，作用是告诉 TCP 协议应该把报文发给哪个**进程**。



:dash:*有一个 IP 的服务端监听了一个端口，它的 TCP 的最大连接数是多少？*

服务端通常固定在某个本地端口上监听，等待客户端的连接请求。

因此，客户端 IP 和 端口是可变的，其理论值计算公式如下:

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzExLmpwZw?x-oss-process=image/format,png)

对 IPv4，客户端的 IP 数最多为 `2` 的 `32` 次方，客户端的端口数最多为 `2` 的 `16` 次方，也就是服务端单机最大 TCP 连接数，约为 `2` 的 `48` 次方。

当然，服务端最大并发 TCP 连接数远不能达到理论上限，会受以下因素影响：

- **文件描述符限制** ，**每个 TCP 连接都是一个文件，如果文件描述符被占满了**，会发生 too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：
  - **系统级**：当前系统可打开的最大数量，通过 cat /proc/sys/fs/file-max 查看；
  - **用户级**：指定用户可打开的最大数量，通过 cat /etc/security/limits.conf 查看；
  - **进程级**：单个进程可打开的最大数量，通过 cat /proc/sys/fs/nr_open 查看；
- **内存限制**，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。

## 2.UDP基础

### **:vertical_traffic_light: UDP协议特点**

*1.面向无连接*

- UDP 是不需要连接，即刻传输数据。

*2. 服务对象*

- UDP 支持一对一、一对多、多对多的交互通信

*3. 可靠性*

- UDP 是尽最大努力交付，不保证可靠交付数据。

*4. 拥塞控制、流量控制*

- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

*5. 首部开销*

- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

*6. 传输方式*

- UDP是面向报文的，对应用层交下来的报文，不合并，不拆分，保留原报文的边界，可能会丢包和乱序。

*7. 分片不同*

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

### :arrow_double_up:UDP头部格式：

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzEyLmpwZw?x-oss-process=image/format,png" alt="UDP 头部格式" style="zoom:67%;" />

- 目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。
- 包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。
- 校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP包。

:vibration_mode: ***为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？***

原因是 TCP 有**可变长**的「选项」字段，而 UDP 头部长度则是**不会变化**的，无需多一个字段去记录 UDP 的首部长度。

:dancer:` UDP头部长度是固定的，为12B(src ip + dest ip) + 8B = 20B`

## 3.TCP 和 UDP 可以使用同一个端口吗？

答案：**可以的**。

传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。

传输层有两个传输协议分别是 TCP 和 UDP，**在内核中是两个完全独立的软件模块。**

当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息**确定送给哪个模块（TCP/UDP）处理**，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。

## 4.TCP连接详解(握手)

### :racehorse:三次握手过程详解

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="TCP 三次握手" style="zoom: 50%;" />

- **第一次握手**：

在连接建立前，通信双方状态都为`CLOSE`。服务端会先打开一个socket文件绑定一个端口进行监听，等待客户端的连接。当客户端发起连接时，客户端会随机初始化序号（Seq）为`client_isn`，并将序号写入TCP首部的<u>32字节序号字段</u>，然后将`SYN`控制位置为1，表示想要发起连接。接着把SYN报文发送给服务器，然后将自己的状态修改为`SYN_SENT`。

- **第二次握手**：

当服务器收到客户端的SYN的报文后，随机初始化一个序号（Seq）`server_isn`并将其放入TCP首部的<u>32字节序号字段</u>，同时根据客户端发送来的序号生成一个确认号（ACK Num）并将其放入<u>32位应答号字段</u>，该确认号为`client_isn + 1`。 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。

- **第三次握手**

客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，并将`SYN`标志位置为`0`，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 `ESTABLISHED` 状态。服务端收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

当三次握手完成后，SYN标志位被置为0，表示成功建立连接，并且**第三次握手是可以携带数据的，前两次握手是不可以携带数据的。**

:nerd_face: ***如何在 Linux 系统中查看 TCP 状态？***

TCP 的连接状态查看，在 Linux可以通过 `netstat -napt` 命令查看。

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221026160057501.png" alt="image-20221026160057501" style="zoom:67%;" />

### :hammer_and_pick:为什么是三次握手而不是两次或四次？

- 三次握手才可以**阻止重复历史连接的初始化** **（主要原因）**
- 三次握手才可以同步双方的初始序列号
- 三次握手才可以避免资源浪费

不使用「两次握手」和「四次握手」的原因：

- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

原因分析如下图：

**两次握手会重复建立两次连接，其中一次是历史连接**

<img src="https://img-blog.csdnimg.cn/img_convert/fe898053d2e93abac950b1637645943f.png" alt="两次握手无法阻止历史连接" style="zoom:80%;" />

### :mag_right: 为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？

主要原因有两个方面：

- 为了防止历史报文被下一个相同四元组的连接接收（主要方面）；
- 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/isn%E7%9B%B8%E5%90%8C.png" alt="img" style="zoom:67%;" />

原因分析：

假设客户端初始化seq为0，向服务端发起连接，当连接建立完成后seq为1。此时以seq=1向服务器发送报文。此时服务器断电重启，需要重新建立TCP连接，如果序列号相同，连接建立完成后，还是以相同的序列号进行报文发送，如果历史发送的报文此时到达，由于序列号相同，仍然会被服务器接收。

但如果每次连接随机生成序号，那么旧报文发过来后，服务器就可根据序号来判断是否是本次连接接收窗口内报文，如果不是则丢弃。可见，**随机化序列号避免旧报文被接收，同时也可防止黑客伪造的相同序列号的 TCP 报文被对方接收**。

:lantern: ***初始序列号 ISN 是如何随机产生的？***

起始 `ISN` 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时。

RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。

- `M` 是一个计时器，这个计时器每隔 4 微秒加 1。
- `F` 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。

可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。

### :first_quarter_moon: 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

:railway_car: **MTU和MSS前置知识:**

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzIzLmpwZw?x-oss-process=image/format,png" alt="MTU 与 MSS" style="zoom:67%;" />

- `MTU`：**最大传输单元。**一个网络包的最大长度，以太网中一般为 `1500` 字节；当IP数据报超过帧的MTU(最大传输单元)时，它将会被分片传输。**分片能发生在发送端或者中转路由器，且在传输过程中可能被多次分片。**在最后的目标机器上这些分片才会被内核的的IP模块重新组装。
- `MSS`：**最大报文段长度。**除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度，用于在TCP连接建立时，收发双方协商通信时每一个**报文段所能承载的最大数据长度**；

对于IPv4，为了避免IP分片，主机一般**默认MSS为536字节** （`576IP最大字节数` - `20字节TCP协议头` - `20字节IP协议头` = `536字节`）。同理，IPv6的主机默认MSS为1220字节（`1280IP最大字节数` - `20字节TCP协议头` - `40字节IP协议头` = `1220字节`）。

**当发送方主机想要调整MSS时，应注意以下几点：**

1. MSS不包含TCP及IP的协议头长度，收到TCP头部的影响。
2. MSS选项只能在初始化连接请求（SYN=1）使用。 
3. 发送方与接收方的MSS不一定相等。

:facepunch:**回答问题：**

IP层是不可靠的，IP层没有实现重传机制，当分片丢失一个，**所有分片都要重传**（即重传整个连接内的数据）。假设一个分片丢失，接收方的 IP 层就无法组装成一个完整的 TCP 报文（头部 + 数据），也就**无法将数据报文送到 TCP 层**，由于无法收到接收方的ACK，发送方会触发超时重传，就会重发「整个 TCP 报文（头部 + 数据）」。

为了达到最佳的传输效能 TCP 协议在**建立连接的时候通常要协商双方的 MSS 值（MSS是由MTU计算出来的）**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，根据MSS，传输层把不超过MSS的数据封装，下压给网络层，**网络层避免了IP包分片**，而接收方也不会出现数据帧超过MTU而无法接收的情况

![握手阶段协商 MSS](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzI0LmpwZw?x-oss-process=image/format,png)

经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。

### :cookie: 第一次握手丢失了，会发生什么？

当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，如果该报文丢失，客户端就收不到服务端的 SYN-ACK 报文，此时就会触发**「超时重传」**机制，重传 SYN 报文，而且**重传的 SYN 报文的序列号都是一样的**。

在 Linux 里，客户端的 SYN 报文最大重传次数由 `tcp_syn_retries`内核参数控制，这个参数是可以自定义的，默认值一般是 5。

```shell
# cat /proc/sys/net/ipv4/tcp_syn_retries
5
```

通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，**每次超时的时间是上一次的 2 倍**。

### :see_no_evil: 第二次握手丢失了，会发生什么？

第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是**客户端就会触发超时重传机制，重传 SYN 报文**。

如果第二次握手丢失了，服务端就收不到第三次握手，于是**服务端这边会触发超时重传机制，重传 SYN-ACK 报文**。

在 Linux 下，SYN-ACK 报文的最大重传次数由 `tcp_synack_retries`内核参数决定，默认值是 5。

```shell
# cat /proc/sys/net/ipv4/tcp_synack_retries
5
```

**因此，当第二次握手丢失了，客户端和服务端都会重传：**

### :last_quarter_moon_with_face: 第三次握手丢失了，会发生什么？

客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 **ACK 报文**，也就是第三次握手，此时客户端状态进入到 `ESTABLISH` 状态。

当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，即服务端认为客户端并未收到第二次握手的信息。注意，**客户端ACK 报文是不会有重传的，当 ACK 丢失了，就由服务端重传对应的报文，然后触发客户端的ACK再次发送**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E4%B8%A2%E5%A4%B1.drawio.png" alt="img" style="zoom: 40%;" />

- 当服务端超时重传 2 次 SYN-ACK 报文后，由于 tcp_synack_retries 为 2（假设），已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第三次握手（ACK 报文），那么服务端就会断开连接。

### :rice: 什么是 SYN 攻击？如何避免 SYN 攻击？

TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accept 队列；

连接建立流程：

- 当服务端接收到客户端的 SYN 报文时，会创建一个**半连接的对象**，然后将其加入到内核的「 SYN 队列」；
- 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；
- 服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到**「 Accept 队列」；**
- 应用通过调用 `accpet()` socket 接口，从「 Accept 队列」取出连接对象，此时连接建立完成。

不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，默认情况都会丢弃报文。

SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样**当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃**，导致客户端无法和服务端建立连接。

**:leaves: 避免 SYN 攻击方式，可以有以下四种方法：**

- 调大 netdev_max_backlog；
- 增大 TCP 半连接队列；
- 开启 tcp_syncookies；
- 减少 SYN+ACK 重传次数

> 方式一：调大 netdev_max_backlog

当**网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。**控制该队列的最大值如下参数，默认值是 1000，我们要适当调大该参数的值，比如设置为 10000：

```bash
net.core.netdev_max_backlog = 10000
```

> 方式二：增大 TCP 半连接队列

增大 TCP 半连接队列，要同时增大下面这三个参数：

- 增大 net.ipv4.tcp_max_syn_backlog
- 增大 listen() 函数中的 backlog
- 增大 net.core.somaxconn

> 方式三：开启 net.ipv4.tcp_syncookies

开启 syncookies 功能就可以在**不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接。**

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzI5LmpwZw?x-oss-process=image/format,png" alt="tcp_syncookies 应对 SYN 攻击" style="zoom:50%;" />

具体过程：

- 当 「 SYN 队列」满之后，后续服务端收到 SYN 包，不会丢弃，而是根据算法，计算出一个 `cookie` 值；
- 将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端；
- 服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。
- 最后应用程序通过调用 `accpet()` 接口，从「 Accept 队列」取出的连接。

可以看到，当开启了 tcp_syncookies 了，即使受到 SYN 攻击而导致 SYN 队列满时，也能保证正常的连接成功建立。

net.ipv4.tcp_syncookies 参数主要有以下三个值：

- 0 值，表示关闭该功能；
- 1 值，表示仅当 SYN 半连接队列放不下时，再启用它；
- 2 值，表示无条件开启功能；

那么在应对 SYN 攻击时，只需要设置为 1 即可。

```bash
$ echo 1 > /proc/sys/net/ipv4/tcp_syncookies
[root@gcs100 ~]# cat /proc/sys/net/ipv4/tcp_syncookies
1 #默认启用
```

> 方式四：减少 SYN+ACK 重传次数

当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。

那么针对 SYN 攻击的场景，我们可以减少 SYN-ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。

SYN-ACK 报文的最大重传次数由 `tcp_synack_retries`内核参数决定（默认值是 5 次），比如将 tcp_synack_retries 减少到 2 次：

```shell
$ echo 2 > /proc/sys/net/ipv4/tcp_synack_retries
```

## 5.TCP连接断开详解

### :office: TCP四次挥手详解

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzMwLmpwZw?x-oss-process=image/format,png" alt="客户端主动关闭连接 —— TCP 四次挥手" style="zoom:67%;" />

- 当客户端准备断开连接时，会发送一个TCP首部`FIN`标志位被设为1的报文（FIN报文），表示想要断开连接，然后变为`FIN_WAIT_1`状态
- 当服务端收到FIN报文后，向客户端发送一个ACK应答报文，然后状态变为`CLOSE_WAIT`
- 当客户端收到ACK应答报文后状态变为`FIN_WAIT_2`
- 等待服务端处理完数据后，接着向客户端发送一个`FIN`报文，然后状态变为`LAST_ACK`
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
- 服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**

### :panda_face: 为什么挥手需要四次？

- 关闭连接时，客户端向服务端发送一个FIN报文，表示客户端不再发送报文但还可以继续接收报文
- 当服务端收到客户端FIN报文会先回复一个ACK表示自己已收到断开连接请求，但此时可能还要处理上次客户端传来但还未处理完的数据
- 当服务端处理完所有消息后，向客户端发送一个FIN报文，表示自己同意断开连接了

从上面过程可知，**服务端通常需要等待完成数据的发送和处理**，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。

:satisfied: 但是**在特定情况下，四次挥手是可以变成三次挥手的**

服务器收到客户端的 FIN 报文时，内核会马上回一个 ACK 应答报文，**但是服务端应用程序可能还有数据要发送，所以并不能马上发送 FIN 报文，而是将发送 FIN 报文的控制权交给服务端应用程序**：

- 如果服务端应用程序有数据要发送的话，就发完数据后，才调用关闭连接的函数；
- 如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，

**是否要发送第三次挥手的控制权不在内核，而是在被动关闭方（上图的服务端）的应用程序，因为应用程序可能还有数据要发送，由应用程序决定什么时候调用关闭连接的函数，当调用了关闭连接的函数，内核就会发送 FIN 报文了，**所以服务端的 ACK 和 FIN 一般都会分开发送。

当被动关闭方在 TCP 挥手过程中，「**没有数据要发送」并且「开启了 TCP 延迟确认机制（默认会开启）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。**

:factory: **什么是 TCP 延迟确认机制？**

当发送没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。 为了解决 ACK 传输效率低问题，所以就衍生出了 **TCP 延迟确认**。 TCP 延迟确认的策略：

- 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方
- 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送
- 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK

**延迟等待的时间**是在 Linux 内核中定义的，如下图：

<img src="https://img-blog.csdnimg.cn/ae241915337a4d2c9cb2f7ab91e6661d.png" alt="img" style="zoom:50%;" />

关键就需要 HZ 这个数值大小，HZ 是跟系统的时钟频率有关，每个操作系统都不一样，在我的 Linux 系统中 HZ 大小是 1000：

```bash
[root@gcs100 ~]# cat /boot/config-3.10.0-1160.el7.x86_64 | grep '^CONFIG_HZ='
CONFIG_HZ=1000
```

### :pancakes: 第一次挥手丢失了，会发生什么？

当客户端（主动关闭方）**调用 close 函数**后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 `FIN_WAIT_1` 状态。

如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

当客户端超时重传 FIN 报文的次数**达到最大重传次数**，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次挥手（ACK报文），那么客户端就会断开连接。

### :ice_cream: 第二次挥手丢失了，会发生什么？

当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 `CLOSE_WAIT` 状态。

ACK 报文是不会主动重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。如果已达到最大重传次数，但还是没能收到服务端的第二次挥手（ACK 报文），那么客户端就会断开连接。

当客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 `FIN_WAIT2` 状态，在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。

**对于 close() 函数关闭的连接，由于无法再发送和接收数据**，所以`FIN_WAIT2` 状态不可以持续太久，而 `tcp_fin_timeout` 控制了这个状态下连接的持续时长，默认值是 60 秒。

这意味着对于**调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭**

### :yellow_heart: 第三次挥手丢失了，会发生什么？

当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 `CLOSE_WAIT` 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。

内核是没有权利替代进程关闭连接，必须由**进程主动调用 close 函数来触发服务端发送 FIN 报文。**

但如果FIN报文丢失，就一直收不到客户端传来的ACK报文来关闭连接，这时就会触发超时重传，重发次数仍然由 `tcp_orphan_retrie`s 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。当达到了重传最大次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK报文），那么服务端就会断开连接。

客户端因为是通过 close 函数关闭连接的，处于 FIN_WAIT_2 状态是有时长限制的，如果 tcp_fin_timeout 时间内还是没能收到服务端的第三次挥手（FIN 报文），那么客户端就会断开连接。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC%E4%B8%89%E6%AC%A1%E6%8C%A5%E6%89%8B%E4%B8%A2%E5%A4%B1.drawio.png" alt="img" style="zoom:50%;" />

### :water_buffalo: 第四次挥手丢失了，会发生什么？

当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 `TIME_WAIT` 状态。

在 Linux 系统，TIME_WAIT 状态会持续 **2MSL** 后才会进入关闭状态

然后，服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态。

如果第四次挥手的 ACK 报文没有到达服务端，**服务端就会重发 FIN 报文**，重发次数仍然由前面介绍过的 `tcp_orphan_retries` 参数控制。客户端进入TIME_WAIT状态后，如果途中再次收到第三次挥手（FIN 报文）后，就会重置定时器，当等待 2MSL 时长后，客户端就会断开连接。

```bash
[root@gcs100 ~]# cat /proc/sys/net/ipv4/tcp_orphan_retries
0 #默认开启重传次数为0
```



<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E4%B8%A2%E5%A4%B1drawio.drawio.png" alt="img" style="zoom:50%;" />

### :japan: 为什么 TIME_WAIT 等待的时间是 2MSL？

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 **IP 数据报可以经过的最大路由数**，每经过一个处理他的路由器此值就减 1，**当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机**。

**TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了**。

#### :kaaba: 原因：

因为客户端不知道服务端是否能收到ACK应答数据包，服务端如果没有收到ACK，会进行重传FIN，考虑最坏的一种情况：第四次挥手的**ACK包的最大生存时长(MSL)+服务端重传的FIN包的最大生存时长(MSL)=2MSL**

 **2MSL时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

`2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。

在 Linux 系统里 `2MSL` 默认是 `60` 秒，那么一个 `MSL` 也就是 `30` 秒。**Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒**。

### :taco: 为什么需要 TIME_WAIT 状态？

需要 TIME-WAIT 状态，主要是两个原因：

- **防止历史连接中的数据，被后面相同四元组的连接错误的接收；**
- **保证「被动关闭连接」的一方，能被正确的关闭；**

*:v: 原因一：防止历史连接中的数据，被后面相同四元组的连接错误的接收*

- 服务端在**关闭连接之前发送**的 `SEQ = 301` 报文，被网络延迟了。
- 接着，服务端以相同的四元组重新打开了新连接，前面被延迟的 `SEQ = 301` 这时抵达了客户端，而且该数据报文的序列号刚好在客户端接收窗口内，因此客户端会正常接收这个数据报文，但是这个数据报文是上一个连接残留下来的，这样就产生数据错乱等严重的问题。

<img src="https://img-blog.csdnimg.cn/img_convert/6385cc99500b01ba2ef288c27523c1e7.png" alt="TIME-WAIT 时间过短，收到旧连接的数据报文" style="zoom: 50%;" />

为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**

*:cactus: 原因二：保证「被动关闭连接」的一方，能被正确的关闭*

TIME-WAIT 作用是**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。**

假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSE 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TIME-WAIT%E8%BF%9E%E6%8E%A5%E6%AD%A3%E5%B8%B8%E5%85%B3%E9%97%AD.drawio.png" alt="TIME-WAIT 时间正常，确保了连接正常关闭" style="zoom:67%;" />

服务端收到这个 RST`连接重置` 并将其解释为一个错误（Connection reset by peer），**这对于一个可靠的协议来说不是一个优雅的终止方式**。

为了防止这种情况出现，客户端必须等待足够长的时间，确保服务端能够收到 ACK，如果服务端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送一个 FIN，**这样一去一来刚好两个 MSL 的时间。**

### :dark_sunglasses: TIME_WAIT 过多有什么危害？

- 第一是**占用系统资源**，比如文件描述符、内存资源、CPU 资源、线程资源等；
- 第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 `32768～61000`，也可以通过 `net.ipv4.ip_local_port_range`参数指定范围。

**如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接**，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。但是，**只要客户端连接的服务器不同，端口资源可以重复使用的，因为一个tcp连接由一个四元组决定**。

**如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多**，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。

### :volcano:连接断开的几个案例

- 客户端进程崩溃
- 服务端进程崩溃
- 拔掉网线
- 网络迁移（如数据换WIFI）

进程崩溃TCP连接是会断开的，即socket消亡；但拔掉网线进程并未崩溃，TCP连接仍然存在。**进程在，socket在；进程亡，socket亡。**

#### I.如果已经建立了连接，但是客户端突然出现故障了怎么办？

`保活机制（由服务器端发起）`

TCP 有一个机制是**保活机制**。定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：

```shell
net.ipv4.tcp_keepalive_intvl = 75 #表示每次检测间隔 75 秒；
net.ipv4.tcp_keepalive_probes = 9 #表示检测 9 次无响应，认为对方是不可达的
net.ipv4.tcp_keepalive_time = 7200 #表示保活时间是 7200 秒
```

如果开启了 TCP 保活，需要考虑以下几种情况：

- 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置.**
- 第二种，对端程序崩溃并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于**没有该连接的有效信息**，**会产生一个 RST 报文**，这样很快就会发现 TCP 连接已经被重置。
- 第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，达到保活探测次数后都未收到响应报文，**TCP 会报告该 TCP 连接已经死亡**。

**只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接**



#### II.如果已经建立了连接，但是服务端的进程崩溃会发生什么？

TCP 的连接信息是由**内核维护**的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。



#### III.拔掉网线后， 原本的 TCP 连接还存在吗？

:family_man_boy_boy: ***拔掉网线后，有数据传输的情况：***

在客户端拔掉网线后，服务端向客户端发送的数据报文会得不到任何的响应，在等待一定时长后，服务端就会触发**超时重传**机制。

**如果在服务端重传报文的过程中，客户端刚好把网线插回去了**，由于**拔掉网线并不会改变客户端的 TCP 连接状态**，并且还是处于 ESTABLISHED 状态，所以这时客户端是可以正常接收服务端发来的数据报文的，然后客户端就会回 ACK 响应报文。

**如果如果在服务端重传报文的过程中，客户端一直没有将网线插回去**，服务端超时重传报文的**次数达到一定tcp_retries2 后**，内核就会判定出该 TCP 有问题，服务端的 TCP 连接就会断开**（四元组消失）**。

等客户端插上网线后，如果客户端向服务端发送报文，由于原来的四元组TCP连接已经不存在了，这时服务端就会发送`RST`报文，表示连接已经重置

在 Linux 系统中，提供了一个叫 tcp_retries2 配置项，默认值是 15：

```shell
[root@gcs100 myredis]# cat /proc/sys/net/ipv4/tcp_retries2
15
```

不过 tcp_retries2 设置了 15 次，并不代表 TCP 超时重传了 15 次才会通知应用程序终止该 TCP 连接，**内核会根据 tcp_retries2 设置的值，计算出一个 timeout**（*如果 tcp_retries2 =15，那么计算得到的 timeout = 924600 ms*），**如果重传间隔超过这个 timeout，则认为超过了阈值，就会停止重传，然后就会断开 TCP 连接**。

在发生超时重传的过程中，每一轮的超时时间（RTO）都是**倍数增长**的，比如如果第一轮 RTO 是 200 毫秒，那么第二轮 RTO 是 400 毫秒，第三轮 RTO 是 800 毫秒，以此类推。

***:gift_heart:拔掉网线后，无数据传输的情况***

针对拔掉网线后，没有数据传输的场景，还得看是否开启了 TCP keepalive 机制 （TCP 保活机制）。

如果**没有开启** TCP keepalive 机制，在客户端拔掉网线后，并且双方都没有进行数据传输，那么客户端和服务端的 TCP 连接将会一直保持存在。

而如果**开启**了 TCP keepalive 机制，在客户端拔掉网线后，即使双方都没有进行数据传输，在持续一段时间后，TCP 就会发送探测报文。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。



#### IV.网络迁移需要重新建立 TCP 连接

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。

![TCP 四元组](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzEwLmpwZw?x-oss-process=image/format,png)

那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。

而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

## 6.Socket网络编程

### :gem:编程基本步骤：

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzM0LmpwZw?x-oss-process=image/format,png" alt="基于 TCP 协议的客户端和服务端工作" style="zoom: 67%;" />

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将 socket 绑定在指定的 IP 地址和端口;
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务端端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

这里需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。

### :satisfied: 没有 accept，能建立 TCP 连接吗？

答案：**可以的，但连接建立后无法进行读写操作**。

accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP **全连接队列取出一个已经建立连接的 socket**，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg" alt="半连接队列与全连接队列" style="zoom:50%;" />

当第一次握手结束，内核就会将socket对象放入半连接队列，当三次握手结束（双方都变为`ESTABLISHED`状态），会将半连接队列里的socket放入全连接队列，此时从内核态切换到用户态，然后服务端再从用户态发起connect系统调用，此时又陷入内核，内核将全连接队列里已经建立的socket取出，通过此socket就可以进行数据的传输了。

### :vertical_traffic_light: accept 发生在三次握手的哪一步？

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/socket%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="socket 三次握手" style="zoom:50%;" />

**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**

### :wave: 客户端调用 close 了，连接是断开的流程是什么？

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzM3LmpwZw?x-oss-process=image/format,png" alt="客户端调用 close 过程" style="zoom:50%;" />

- 客户端调用 `close`，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态；
- 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 `EOF` 到接收缓冲区中，应用程序可以通过 `read` 调用来感知这个 FIN 包。这个 `EOF` 会被**放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 `CLOSE_WAIT `状态；
- 接着，当处理完数据后，自然就会读到 `EOF`，于是也调用 `close` 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态；
- 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；
- 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；
- 客户端经过 `2MSL` 时间之后，也进入 CLOSE 状态

**客户端在调用close()函数的时候会发送FIN报文，当服务端收到FIN报文并处理完所有数据后再调用close()并发送FIN报文。**

## 7. TCP重传机制、流量控制、拥塞控制详解

### :lemon: TCP可靠数据传输原理

有两种思路来实现TCP可靠数据传输：

- **停等协议：**双发每次只传输一个分组，并且要等待对方的ACK才传输下一个分组，信道利用率低，因为大部分时间信道是空闲的（传输链路）。
- **流水线可靠数据传输协议**：不必等待上一个分组的ACK，可以一次连续传输多个分组，信道在大部分时间是充满报文的。

:v:**信道利用率**：

分组在信道上传输的时间为TD（L / R），分组确认时间为TA ,往返时间为RTT。

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221027142653924.png" alt="image-20221027142653924" style="zoom:67%;" />

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221027143043920.png" alt="image-20221027143043920" style="zoom:67%;" />

由于停等协议效率极低，不实用，所以目前TCP的可靠传输都是**基于流水线可靠传输**展开的。

**流水线可靠传输的也要又差错恢复机制来保证，所以之后的重传机制，滑动窗口等都是为其做担保。**

### :keyboard: 滑动窗口:

在传输流水线中，允许发送方发送多个分组（当多个分组可用时）而不需要等待确认，但它受限于在流水线中未确认分组的分组数不能超过某个最大允许数N，**N常被称作窗口长度**。它对应于TCP头中的`Window`字段，滑动窗口被分为**发送方窗口**和**接收方窗口**。滑动窗口与分组的重传以及流量控制与拥塞控制都有联系。

窗口的实现实际上是**操作系统开辟的一个缓存空间（Buffer）**，发送方主机在等到确认应答返回之前，必须在**缓冲区中保留已发送的数据。**如果按期收到确认应答，此时数据就可以从缓存区清除。

TCP 头里有一个字段叫 `Window`，也就是窗口大小。

**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

**通信双方的端系统都会同时维护一个发送窗口和接收窗口，**因为发送和接收都是相对对方而言的。

:cake: **发送方的滑动窗口**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/16.jpg?" alt="img" style="zoom:50%;" />

- 基序号（base）：最早未确认分组的序号（对应上图32）
- 下一个序号（nextseqnum）：最小的未使用序号（对应上图46）

- 滑动窗口的大小： 

`N` = 发送但未收到ACK确认的分组序号`[base,nextseqnum - 1] `+ 未发送但可用分组序号`[nextseqnum, base + N - 1]` 

当发送方把数据「全部」都一下发送出去后，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。

当未确认分组收到ACK报文后，窗口就继续向前移动，收到几个字节的ACK就向前移动几个字节

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/18.jpg" alt="32 ~ 36 字节已确认" style="zoom:50%;" />

TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/19.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="SND.WND、SND.UN、SND.NXT" style="zoom:50%;" />

- `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）；
- `SND.UNA`（*Send Unacknoleged*）：是一个**绝对指针**，它指向的是已**发送但未收到确认的第一个字节的序列号**。
- `SND.NXT`：也是一个**绝对指针**，它指向未发送但可发送范围的第一个字节的序列号。

:lantern:**接收方的滑动窗口(rwnd)：**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/20.jpg" alt="接收窗口" style="zoom:57%;" />

其中三个接收部分，使用两个指针进行划分:

- `RCV.WND`：表示接收窗口的大小，它会通告给发送方。
- `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。
- 指向 #4 的第一个字节是个相对指针，它需要 `RCV.NXT` 指针加上 `RCV.WND` 大小的偏移量，就可以指向 #4 的第一个字节了

:link: **接收窗口和发送窗口的大小是相等的吗**？

并不是完全相等，接收窗口的大小是**约等于**发送窗口的大小的。

因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Window 字段来告诉发送方。那么这个传输过程是存在时延的，所以**接收窗口和发送窗口是约等于的关系。**

### I.重传机制

 TCP 针对数据包丢失的情况，会用**重传机制**解决。

常见的重传机制有：

:x: **注意：前面两种只是一种重传的策略，并不是TCP采用的重传策略。**

- 超时重传
- 快速重传
- SACK（选择确认）
- DACK（Duplicate SACK）

#### :jack_o_lantern:**超时重传（存在超时周期可能相对较长问题）**：

超时重传就是再发送数据包给对方的时候会设置一个定时器，如果在设定时间内**没有收到对方回送的ACK报文**，就会重发数据。

TCP 会在以下两种情况发生超时重传：

- 数据包丢失
- 确认应答丢失

> 超时时间应该设置为多少呢？

`RTT`（Round-Trip Time 往返时延）：是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。

`RTO` （Retransmission Timeout 超时重传时间）：数据包发出后开始计时，直到接收到应答报文这段时间内如果超过RTO就会触发重传。

- 当超时时间 **RTO 较大**时，重发就慢，没有效率，性能差；
- 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增**加网络拥塞，导致更多的超时**，更多的超时导致更多的重发。

根据上述的两种情况可分析出，**超时重传时间 RTO 的值应该略大于报文往返 RTT 的值**。

#### :doughnut:**快速重传（未解决重传一个还是重传所有的问题）**：

**不以时间为驱动，而是以数据驱动重传**，超时重传存在超时时间周期可能相对较长，效率较低，而快速重传能通过冗余ACK来较好地检测到丢包的情况，进而解决超时重传效率低下这一问题。

**冗余ACK**就是发送方多次接收到同一个报文段的ACK。正常情况下，一个报文段对应一个ACK，但如果丢包了，接收方就会反复传输上一个报文的ACK报文给发送方。如果发送方**接收到了3个冗余ACK，就会触发快速重传。**在**收到三个冗余ACK前的这段时间发送方还在继续发送报文，但这些报文会被接收方丢弃。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/10.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="快速重传机制" style="zoom:67%;" />

但问题来了，如上图：

发送方收到三个冗余ACK触发快速重传，那么是从丢失的那个分组开始重传还是仅重传丢失的报文？

有两种方式来解决这一问题：

- **回退N步（GBN）:**接收方直接丢弃失序的分组，反复向发送方重传冗余ACK，等待发送方超时时间发生，从丢失的分组开始，发送方发送所有`已发送但未确认`的分组。

  **GBN存在一个性能问题**：单个分组的时序就会引起大量分组的重传，随着信道差错率的增加，信道可能充斥着很多不必要重传的分组，这会使链路变得拥塞。

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vcmVhc3QxbnBlYWNlL3BpY3R1cmUvcmF3L21hc3Rlci8lRTglQUUlQTElRTclQUUlOTclRTYlOUMlQkElRTclQkQlOTElRTclQkIlOUMvUVEyMDIwMDQyMC0yMTAyMDhAMnguanBn?x-oss-process=image/format,png" alt="查看源图像" style="zoom:20%;" />

- **选择重传（SR）：**让发送方仅重传那些它怀疑在接收方出错（丢失或受损）的分组而避免了不必要的重传。**失序的分组将被缓存直至所有丢失分组都被收到为止。**

#### :camping:**选择确认（SACK）**：

还有一种实现重传机制的方式叫：`SACK`（ Selective Acknowledgment）， **选择性确认**。

发送方仅需维护已发送但`未确认的字节的最小序号（SendBase）`和一个`下一个要发送的字节的序号（NextSeqNum）`，接收方需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 `SACK` 信息发现只有 `200~299` 这段数据丢失，则重发时，就**只选择了这个 TCP 段进行重复**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/11.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="选择性确认" style="zoom:50%;" />

如果要支持 `SACK`，必须双方都要支持。在 Linux 下，可以通过 `net.ipv4.tcp_sack` 参数打开这个功能（Linux 2.4 后默认打开）。

#### **:fallen_leaf: Duplicate(重复) SACK：**

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

*Exmp1：ACK 丢包*

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/12.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="ACK 丢包" style="zoom:67%;" />

- 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）
- **于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500**，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 `D-SACK`。
- 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。

*Exmp2：网络延时*

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/13.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="网络延时" style="zoom:67%;" />

- 数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。
- 而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；
- **所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。**
- 这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。

可见，`D-SACK` 有这么几个好处：

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

发送方得到了接收方的结果反馈，就可以对事件进行编程，进行一些特定的处理。

在 Linux 下可以通过 `net.ipv4.tcp_dsack` 参数开启/关闭这个功能（Linux 2.4 后默认打开）。

### II.流量控制

**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**TCP为它的应用程序提供流量控制服务，流量控制的目的是为了**避免发送方发送的分组填满接收方的缓存（接收窗口）。**TCP让发送方维护一个接收窗口，接收窗口用于指示--该接收方还有多少可用的缓存空间。由于TCP是全双工的，所以在连接两端都维护一个接收窗口。



<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/21.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="流量控制" style="zoom:50%;" />



:question: 注意在上面这个例子中，**接收窗口的大小（rwnd）是没有变化，相当于只是随着接收分组平移。固定**的，它会但rwnd并不是绝对不变的，它会随着操作系统的接收缓存而发生变化。rwnd必须满足 ：

**rwnd = RcvBuffer - [LastByteRcvd - LastByteRead]**

如果TCP接收缓存**读取的速度跟不上接收速度**，接收窗口是会减小的。

当接收窗口的大小发生改变时，接收方在发送ACK分组给发送方时会**顺便将自己rwnd大小告诉发送方，发送方会根据这个值动态地调整自己的发送窗口。**

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221027170315993.png" alt="image-20221027170315993" style="zoom:30%;" />

#### :volcano: 操作系统缓冲区与滑动窗口的关系

发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会**被操作系统调整**。

当应用进程没办法及时读取缓冲区的内容时，也会对我们的缓冲区造成影响。

#### :dagger:`Exmp1:`



<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/22.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="img" style="zoom:43%;" />

从上述案例可以看出，**当接收窗口的大小发生改变时，接收方在发送ACK分组给发送方时会顺便将自己rwnd大小告诉发送方，发送方会根据这个值动态地调整自己的发送窗口。**

#### :e-mail:`Exmp2`

当服务端系统资源非常紧张的时候，操作系统可能会直接减少了接收缓冲区大小，这时应用程序又无法及时读取缓存数据，那么这时候就有严重的事情发生了，会出现数据包丢失的现象。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/23.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="img" style="zoom:43%;" />

如果发生了**先减少缓存，再收缩窗口，就会出现丢包的现象。**

**为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。**

### :calling: 发送方窗口关闭

在前面我们都看到了，TCP 通过让接收方指明希望从发送方接收的数据大小（窗口大小）来进行流量控制。

**如果接收窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。**

> 窗口关闭潜在的危险

接收方向发送方通告窗口大小时，是通过 `ACK` 报文来通告的。

那么，当接收方的发送窗口大小减为0时，这时就会通知发送方，发送方得知接受方接收窗口已经为0了，这时就会发生发送窗口关闭，当**发送窗口关闭，发送发就不再处理数据了**。如果此时接收方处理完数据后，向发送方通告一个窗口非 0 的 ACK 报文，如果**这个通告窗口的 ACK 报文在网络中丢失了**，那麻烦就大了。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/24.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="窗口关闭潜在的危险" style="zoom:50%;" />

这会导致**发送方一直等待接收方的非 0 窗口通知**，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。

> TCP 是如何解决窗口关闭时，潜在的死锁现象呢？

为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**

如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**来打破死锁局面，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/25.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="窗口探测" style="zoom:50%;" />

- 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
- 如果接收窗口不是 0，那么死锁的局面就可以被打破了。

窗口探测的次数**一般为 3 次**，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 `RST` 报文来中断连接。

### :hole:糊涂窗口综合症

如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的**发送窗口越来越小。**

到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症。**我们要知道TCP 报文首部就占 20 字节了，如果每次接收方只允许发送方发送两三个字节，那就**为了传输这么几个有效的字节，还得附加上 20 字节的数据，这就是很浪费资源性能的。**

解决糊涂窗口综合症，就要同时解决上面两个问题就可以了：

- 让接收方不通告小窗口给发送方
- 让发送方避免发送小数据

:vhs: **怎么让接收方不通告小窗口呢？**

**接收方**通常的策略如下:

当「窗口大小」小于 **`min( MSS，缓存空间/2 ) `**，也就是小于 MSS`（发送的分组还达不到报文段所能承载的最大数据长度） `与 1/2 缓存大小中的最小值时，就会向发送方**通告窗口为 `0`**，也就阻止了发送方再发数据过来。

等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。

:baby_chick: **怎么让发送方避免发送小数据呢？**

**发送方**通常的策略如下:

使用 Nagle 算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才可以发送数据：

- 条件一：要等到**窗口大小 >= `MSS` 并且 数据大小 >= `MSS`**；
- 条件二：收到之前发送数据的 `ack` 回包；

Nagle 伪代码如下：

```c
if 有数据要发送 {
    if 可用窗口大小 >= MSS and 可发送的数据 >= MSS {
    	立刻发送MSS大小的数据
    } else {
        if 有未确认的数据 {
            将数据放入缓存等待接收ACK
        } else {
            立刻发送数据
        }
    }
}
```

只要上面两个条件都不满足，**发送方一直在囤积数据**，直到满足上面的发送条件。

**Nagle 算法默认是打开的**，如果对于一些需要**小数据包交互的场景的程序**，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。

可以在 Socket 设置 `TCP_NODELAY` 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）

```c
setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&value, sizeof(int));
```

:nail_care: 综上，**接收方得满足「不通告小窗口给发送方」+ 发送方开启 Nagle 算法，才能避免糊涂窗口综合症**。

### III.拥塞控制

计算机网络大多都处在一个共享的链路环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。

在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包**时延、丢失等，这时 TCP 就会重传数据**，但是**一重传就会导致网络的负担更重**，于是会导致更大的延迟以及更多的丢包，如此就进入了一个恶性循环。

于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**

为了在「发送方」调节所要发送数据的量，定义了一个叫做「**拥塞窗口**」的概念。

#### :video_game: 什么是拥塞窗口？和发送窗口有什么关系呢？

**拥塞窗口 cwnd `( congestion window )`**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

我们在前面提到过发送窗口 `swnd` 和接收窗口 `rwnd` 是**约等于**的关系，那么由于加入了拥塞窗口的概念后，此时**发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。**

拥塞窗口 `cwnd` 变化的规则：

- 只要网络中没有出现拥塞，`cwnd` 就会增大；
- 但网络中出现了拥塞，`cwnd` 就减少；

#### :name_badge: 怎么知道当前网络是否出现了拥塞呢？

当TCP发送方感知到“丢包事件”，那么就可判断网络上出现拥塞。丢包事件是指：**出现超时重传或收到来自接收方的三个冗余ACK。**

#### :first_quarter_moon_with_face:TCP的拥塞控制算法详解：

该算法包括以下几个主要部分：

- 慢启动
- 拥塞避免
- 拥塞发生
- 快速恢复

**:desert_island: 慢启动**：

当一条TCP连接开始时，cwnd的值通初始置为一个MSS，这就使得初始发送速率大约为 MSS/RTT。对于TCP发送方而言，可用带宽可能比MSS/RTT大得多，TCP发送方希望迅速找到更大可用的带宽大小，因此在慢启动状态，cwnd值以1个MSS开始并且当第一次传输的报文被确认后就增加1个MSS变为2MSS，然后下一次又变为4MSS，8MSS，16MSS。因此TCP发送速率起始慢，但**发送速率在慢启动阶段以指数型增长。**

***慢启动何时结束？***

在慢启动阶段：

- 第一种方式：如果存在一个超时指示的丢包事件（发生拥塞），TCP发送方将会把cwnd重置为1并重新开始慢启动。它还将第二个状态变量的值ssthresh（慢启动阈值）设置为cwnd / 2。

- 第二种方式：当cwnd等于ssthresh时，转移到**拥塞避免模式**。

- 第三种方式：如果检测到3个冗余ACK，TCP进行一次快速重传，并进入**快速恢复状态**。

:heart_decoration:**拥塞避免**：

拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。

一般来说 `ssthresh` 的大小是 `65535` 字节。

那么进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

假定 `ssthresh` 为 `8`，当cwnd的值达到8时，就不再以指数级增长而转为**线性增长**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/28.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="拥塞避免" style="zoom: 67%;" />

就这么一直增长下去，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。

当触发了重传机制，也就进入了「拥塞发生算法」。

**强调：**“拥塞避免”并非指完全能够避免了拥塞。利用以上的措施要完全避免网络拥塞还是不可能的。“拥塞避免”是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，**使网络比较不容易出现拥塞。**

:camping: **拥塞发生(Tahoe算法)**

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

- 超时重传：到达超时时间引发的重传
- 快速重传：收到三个冗余ACK引发的重传

当发生了「超时重传」，则就会使用拥塞发生算法**（Tahoe算法）**。此时TCP发送方将会把**cwnd重置为1**并重新开始慢启动。它还将第二个状态变量的值**ssthresh（慢启动阈值）设置为cwnd / 2**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/29.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="拥塞发送 —— 超时重传" style="zoom:50%;" />

发生快速重传的拥塞发生算法

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;

:mahjong:**快速恢复（Reno算法）：**

**快速重传和快速恢复算法一般同时使用**，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。

进入快速恢复之前，`cwnd` 和 `ssthresh` 已被更新了：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;

然后，进入快速恢复算法如下：

- **`cwnd = cwnd / 2`**：根据当前cwnd计算出新的ssthresh
- **`ssthresh = cwnd`**

- 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
- 重传丢失的数据包；
- 如果再收到重复的 ACK，那么 cwnd 增加 1；
- 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="快速重传和快速恢复" style="zoom: 67%;" />

![img](https://img-blog.csdn.net/20150925125056948)

#### :o: IV.小总结

 [1].流量控制：在TCP连接上实现对发送流量的控制，考虑点对点之间对通信量的控制，**端到端**，即：控制发送端的数据发送速率，使接收端可以来得及接收，保证网络高效稳定运行。 

[2].拥塞控制：处理网络拥塞现象，考虑网络能够承受现有的网络负荷，**全局性变量，涉及所有的路由器、主机以及与降低网络传输性能有关的因素。**防止过多的数据注入到网络，使网络中的路由器或链路不致过载，确保通信子网可以有效为主机传递分组。

## 8.内容补充

#### I.如何解决TCP粘包问题

粘包的问题出现是因为**不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。**

一般有三种方式分包的方式：

- 固定长度的消息；
- 特殊字符作为边界；
- 自定义消息结构。

**固定长度的消息**

这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。

但是这种方式灵活性不高，实际中很少用。

**特殊字符作为边界**

我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。

HTTP 是一个非常好的例子。

<img src="https://img-blog.csdnimg.cn/img_convert/a49a6bb8cd38ae1738d9c00aec68b444.png" alt="图片" style="zoom:67%;" />

HTTP 通过设置**回车符、换行符**作为 HTTP 报文协议的边界。

有一点要注意，这个作为边界点的特殊字符，**如果刚好消息内容里有这个特殊字符，我们要对这个字符转义**，避免被接收方当作消息的边界点而解析到无效的数据。

**自定义消息结构**

我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。

比如这个消息结构体，**首先 4 个字节大小的变量来表示数据长度**，真正的数据则在后面。

```c
struct { 
    u_int32_t message_length; 
    char message_data[]; 
} message;
```

当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。

# 四、网络层

## 1.网络层概述

网络层能被分解为相互作用的两部分，即**数据平面**和**控制平面**。

- 数据平面：决定到达路由器输入链路的数据报（网络层的分组）如何**转发**到该路由器的输出链路之一。数据平面唯一实现的功能就是转发。**转发**是指分组从一个输入链路接口转移到输出链路接口的**路由器本地动作**。
- 控制平面：控制数据报沿着源主机到目的主机的端到端路径种路由器的路由方式。控制平面实现的功能是**路由选择 **。 **路由选择**是指分组从**源主机到目的主机**这种端到端的网络路径处理范围，路由选择功能通常由**软件来实现**。

每台路由器都包含转发和路由选择两种功能。实现转发功能的关键元素就是**转发表**，实现路由选择的关键元素是**路由选择协议**以及路由**选择算法**等。

## 2.IP地址基础

### :man:IP简介

IP的作用： IP 负责在**「没有直连」**的两个网络之间进行通信传输。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/3.jpg" alt="IP 的作用与 MAC 的作用" style="zoom:67%;" />

在数据包在网络传输的过程中，MAC地址每到达一个路由器或主机，源MAC地址和目的MAC地址就发生改变，而源IP和目的IP一般是不会改变的，一般来说局域网内是如此。但如果是在广域网，使用了`NAT`协议，IP是会发生改变的。

### :jack_o_lantern:路由器工作原理：

![image-20221028160231642](C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221028160231642.png)

- 输入端口：终结入物理链路的物理层功能，执行查找功能，**通过查询转发表决定路由器的输出端口**，到达的分组通过路由器的**交换结构**转发到输出端口。
- 交换结构：将路由器的输入端口连接到它的输出端口。
- 输出端口：存储从交换结构接收的分组，通常与该链路的输入端口成对出现在同一线路卡上。
- 路由选择处理器：可以看作一个CPU，执行路由选择协议（控制平面），维护路由选择表与关联链路状态信息，并通过路由选择算法为而该**路由器计算转发表。**

:canoe: **交换结构**：

<img src="https://img-blog.csdnimg.cn/20210701184819348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ2MTAxODY5,size_16,color_FFFFFF,t_70" alt="img" style="zoom:50%;" />

- 经内存交换：不能同时转发两个分组，即使有不同的目的端口，因为经过共享系统总线一次仅能执行一个内存读写。
- 经总线交换：输入端口经一根共享总线将分组直接传送到输出端口，不需要路由选择处理器的干预。
- 经互联网络交换：非阻塞的，只要没有其它分组当前被转发到该输出端口，转发将不会被阻塞。

### :ice_cream:IP地址的格式与分类

:lantern: **IPv4格式：**

IP 地址（IPv4 地址）由 `32` 位正整数来表示，IP 地址在计算机是以二进制的方式处理的。

而人类为了方便记忆采用了**点分十进制**的标记方式，也就是将 32 位 IP 地址以每 8 位为组，共分为 `4` 组，每组以「`.`」隔开，再将每组转换成十进制。

IP 地址最大值也就是 2^32 = 4294967296,也就说，最大允许 43 亿台计算机连接到网络。

**IP 地址并不是根据主机台数来配置的，而是以网卡。**像服务器、路由器等设备都是有 2 个以上的网卡，也就是它们会有 2 个以上的 IP 地址。

:video_game: **IP 地址的分类：**

互联网诞生之初，IP 地址显得很充裕，于是计算机科学家们设计了**分类地址**。

IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/7.jpg" alt="IP 地址分类" style="zoom:55%;" />

上图中黄色部分为分类号，用以**区分 IP 地址类别。**

其中对于 A、B、C 类主要分为两个部分，分别是**网络号和主机号**。网络标识该IP属于哪个链路，主机号标识该主机是哪个网络中的哪个主机。可将网络号比作家庭住址，主机号比作家庭成员个体。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/8.jpg" alt="img" style="zoom:80%;" />

最大主机数的计算公式：`2^主机号位数 - 2`

**为什么要减2？**

- 主机号全为 1 指定某个网络下的所有主机，**用于广播**
- **主机号全为 0 指定某个网络**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/10.jpg" alt="img" style="zoom:67%;" />

:heart_eyes: **广播地址用于什么？**

广播地址用于在**同一个链路中相互连接的主机之间发送数据包**。

广播地址可以分为**本地广播**和**直接广播**两种。

- **在本网络内广播的叫做本地广播**。例如网络地址为 192.168.0.0/24 的情况下，广播地址是 192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0/24 以外的其他链路上。
- **在不同网络之间的广播叫做直接广播**。例如网络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0/24，从而使得所有 192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有一定的安全问题，**多数情况下会在路由器上设置为不转发**） 。

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221028142632561.png" alt="image-20221028142632561" style="zoom:75%;" />

:racing_car: **什么是 D、E 类地址？**

而 D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于**多播**，E 类是预留的分类，**暂时未使用**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/12.jpg" alt="img" style="zoom:67%;" />

:tada: **多播（组播）地址用于什么**？

多播用于**将包发送给特定组内的所有主机。**

由于**本地广播无法穿透路由**，若想给其他网段发送同样的包，就可以使用可以**穿透路由的多播**。

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221028143358805.png" alt="image-20221028143358805" style="zoom:67%;" />

多播使用的 D 类地址，其**前四位**是 `1110` 就表示是**多播地址**，而剩下的 **28 位**是**多播的组编号**。

从 224.0.0.0 ~ 239.255.255.255 都是多播的可用范围，其划分为以下三类：

- 224.0.0.0 ~ 224.0.0.255 为预留的组播地址，**只能在局域网中**，路由器是不会进行转发的。
- 224.0.1.0 ~ 238.255.255.255 为用户可用的组播地址，**可以用于 Internet 上**。
- 239.0.0.0 ~ 239.255.255.255 为本地管理组播地址，可供内部网在内部使用，仅在**特定的本地范围内**有效。

:barber:**IP分类的优缺点**：

***优点***：

不管是路由器还是主机解析到一个 IP 地址时候，我们判断其 IP 地址的首位是否为 0，为 0 则为 A 类地址，为1则继续判断下一位，那么就能很快的找出网络地址和主机地址。所以，这种分类地址的优点就是**简单明了、选路（基于网络地址）简单**。

***缺点***

- **同一网络下没有地址层次**，比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就**缺少地址的灵活性**。

- **不能很好的与现实网络匹配：**
  - C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计一个网吧都不够用。
  - 而 B 类地址能包含的最大主机数量又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。

### :basketball: 无分类地址 CIDR

**CIDR：无类别域间路由选择（Classless Interdomain Routing）**

正因为 IP 分类存在许多缺点，所以后面提出了无分类地址的方案，即 `CIDR`。

这种方式**不再有分类地址的概念**，32 比特的 IP 地址被划分为两部分，前面是**网络号**，后面是**主机号**。

表示形式 `a.b.c.d/x`，其中 `/x` 表示前 x 位属于**网络号**， x 可以是 `0 ~ 32`任意数。

比如 **10.100.122.2/24**，这种地址表示形式就是 **CIDR**，/24 表示前 24 位是网络号，剩余的 8 位是主机号。

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221028144226271.png" alt="image-20221028144226271" style="zoom:67%;" />

#### :call_me_hand: **子网掩码是什么**？

**子网掩码**：掩码的意思就是**掩盖掉主机号**，剩余的就是网络号，子网掩码网络号部分全为1，主机号部分全为0。

**将子网掩码和 IP 地址按位计算 AND，就可得到网络号。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/16.jpg" alt="img" style="zoom:70%;" />

#### :baseball: **为什么要分离网络号和主机号**？

因为两台计算机要通讯，首先要判断是否处于同一个广播域内(在同一链路)，即网络地址是否相同。如果在同一广播域内，就直接可以把数据包转发给它而不用经过路由器，如果不同，则要根据路由寻址的结果转发到对应的网络。

**路由器寻址**工作中，也就是通过这样的方式来找到对应的网络号的，进而**把数据包转发给对应的网络内**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/17.jpg" alt="IP地址的网络号" style="zoom:67%;" />

#### :volleyball: **怎么进行子网划分**？

**子网划分**就是在网络内部将一个网络块进行划分以供多个内部网络使用，对外仍是一个网络

通过子网掩码划分出网络号和主机号，那实际上子网掩码还有一个作用，那就是**划分子网**，将一个广播域再进一步划分为多个子网。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/18.jpg" alt="img" style="zoom:67%;" />

- 未做子网划分的 ip 地址：网络地址＋主机地址
- 做子网划分后的 ip 地址：网络地址＋（子网网络地址＋子网主机地址）

假设对 C 类地址进行子网划分，网络地址 192.168.1.0，使用子网掩码 255.255.255.192 对其进行子网划分。

C 类地址中前 24 位是网络号，最后 8 位是主机号，根据子网掩码可知**从 8 位主机号中借用 2 位(`2^7 + 2^6`)作为子网号**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/19.jpg" alt="img" style="zoom:67%;" />

由于子网网络地址被划分为两位，那么子网地址就有4个，分别是00，01，10，11。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/20.jpg" alt="img" style="zoom:50%;" />

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/21.jpg" alt="img" style="zoom:67%;" />

:level_slider: **为什么要子网划分**？

- 减少网络流量。子网定义了一个网络最大的广播空间（受限广播），可以**减少网络流量**
- 提高网络性能。如果不划分子网，那么我们的网络将是一个巨大的、扁平的网络空间，这将导致网络性能下降。（寻址变慢了）
- 便于网络管理。分层次的网络可以更加方便网络管理员对于网络的管理，就类似于学校要分年级，年级要分班。
- 根据项目的大小灵活分配所需IP

### :detective: 公有IP和私有IP介绍

在 A、B、C 分类地址，实际上又分为公有 IP 地址和私有 IP 地址。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/22.jpg" alt="img" style="zoom:67%;" />

平时我们办公室、家里、学校用的 IP 地址，一般都是**私有 IP 地址**。因为这些地址**允许组织内部的 IT 人员自己管理**、自己分配，而且可以重复。因此，你学校的某个私有 IP 地址和我学校的可以是一样的。

公有 IP 地址是有个**组织统一分配**的，假设你要开一个博客网站，那么你就需要去申请购买一个公有 IP，这样全世界的人才能访问。并且公有 IP 地址基本上要在**整个互联网范围内保持唯一**。

:violin: **公有 IP 地址由谁管理呢？**

私有 IP 地址通常是内部的 IT 人员管理，公有 IP 地址是由 `ICANN` 组织管理，中文叫「互联网名称与数字地址分配机构」。

IANA 是 ICANN 的其中一个机构，它负责分配互联网 IP 地址，是按州的方式层层分配。

### :night_with_stars: IP 地址与路由控制

IP地址的**网络地址**这一部分是用于进行路由控制。

**路由控制表**中记录着网络地址与下一步应该发送至路由器的地址。在**主机和路由器上都会有各自的路由器控制表。**

在发送 IP 包时，首先要确定 IP 包首部中的**目标地址**，再从路由表中找出与该目标地址网络号前缀匹配的网络地址的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由表中由多条记录的前缀能与之匹配上，就选择相同位数最多的网络地址，也就是**最长前缀匹配。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/25.jpg" alt="IP 地址与路由控制" style="zoom:50%;" />

:camera_flash: **环回地址是不会流向网络**

环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。

计算机使用一个特殊的 IP 地址 **127.0.0.1 作为环回地址**。与该地址具有相同意义的是一个叫做 `localhost` 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。

### :violin: IP数据报格式：

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221028162818493.png" alt="image-20221028162818493" style="zoom:67%;" />

- 版本号：`4bit`，规定IP版本；
- 首部长度：`4bit`，记录IP数据报首部的长度，长度不固定，由可选字段长度决定。
- 服务类型：使不同类型的IP数据报能相互区分。例如，将实时数据报（IP电话应用）与非实时数据报（FTP）区分。
- 数据报长度：`16bit`，记录IP数据报的总长度（IP首部+数据）
- 标识、标志、片偏移：与IP分片有关。
- 生存时间（TTL）：确保数据报不会永远在网络中循环。TTL减为0，路由器直接丢弃。
- 首部校验和：用于帮助路由器检测收到的IP数据报中的比特错误。注意IP层只是对IP首部计算了检验和，而TCP/UDP是对整个报文段进行校验。

### :left_luggage:IP分片与重组：

链路层承载的最大数据量叫做**最大传输单元（MTU）**，每种数据链路的最大传输单元 `MTU` 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节等。

每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。

当 IP 数据包**大小大于 MTU** 时， IP 数据包就会被**分片**。

经过分片之后的 IP 数据报在被**重组**的时候，只能由**目标主机进行**，**路由器是不会进行重组的。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/26.jpg" alt="分片与重组" style="zoom:67%;" />

在分片传输中，一旦某个分片丢失，则会造成整个 IP 数据报作废，所以 TCP 引入了 `MSS` 也就是在 TCP 层进行分片不由 IP 层分片，那么对于 UDP 我们尽量不要发送一个大于 `MTU` 的数据报文。

### :car:从IPv4到IPv6迁移：

IPv4 的地址是 32 位的，大约可以提供 42 亿个地址。IPv6 的地址是 `128` 位的，分配的地址数量可谓是取之不尽用之不竭。

**:national_park: IPv6 的亮点:**

- IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址，真是**便捷到即插即用**啊。
- IPv6 包头包首部长度采用固定的值 `40` 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大**提高了传输的性能**。
- IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大**提升了安全性**。

:vibration_mode:**IPv6的标识方法：**

IPv6 地址长度是 128 位，是以每 16 位作为一组，每组用冒号 「:」 隔开。

![IPv6 地址表示方法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/27.jpg)

如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号 「::」隔开。但是，一个 IP 地址中**只允许出现一次两个连续的冒号。**

![Pv6 地址缺省表示方](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/28.jpg)

:handbag: **IPv6 地址的分类：**

- 单播地址，用于一对一的通信
- 组播地址，用于一对多的通信
- 任播地址，可以使数据报交付给**一组主机中的任意一个**，用于通信最近的节点，最近的节点是由路由协议决定
- 没有广播地址

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/29.jpg" alt="IPv6地址结构" style="zoom:67%;" />

:wave: **IPv6 单播地址类型：**

对于一对一通信的 IPv6 地址，主要划分了三类单播地址，每类地址的有效范围都不同。

- 在**同一链路单播通信**，不经过路由器，可以使用**链路本地单播地址**，IPv4 没有此类型
- 在**内网里单播通信**，可以使用**唯一本地地址**，相当于 IPv4 的私有 IP
- 在**互联网通信**，可以使用**全局单播地址**，相当于 IPv4 的公有 IP

:ice_skate:**IPv6首部：**

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221028170215620.png" alt="image-20221028170215620" style="zoom:67%;" />

- **取消了首部校验和字段。** 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。
- **取消了分片/重新组装相关字段。** 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度，如果路由器收到的IPv6数据报因太大而不能被转发到链路上，路由器只需丢弃该报文并向发送方回复“分组太大”的ICMP报文。
- **取消选项字段。** 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 `40` 字节。

## 3.路由协议详解

### I.路由协议简介

在互联网中，一个**自治系统(AS)**是一个有权自主地决定在本系统中应采用何种路由协议的小型单位。这个网络单位可以是一个简单的网络也可以是一个由一或多个普通的网络管理员来控制的网络群体，它是一个单独的可管理的网络单元（例如一所大学，一个企业或者一个公司个体）。

一个自治系统将会分配一个全局的唯一的16位号码，有时我们把这个号码叫做自治系统号（ASN）

在进行三层通信时，除了静态配置路由信息，还可以通过动态获取路由条目，而这就需要使用路由协议来帮助我们了。

**根据管理范围的不同，路由协议可以分为两个大类：**

1. **IGP:内部网关协议（Interior Gateway Protocol）**

内部网关协议（IGP）是一种**专用于一个自治网络系统**（比如：某个当地社区范围内的一个自治网络系统）中网关间交换数据流转通道信息的协议。网络IP协议或者其他的网络协议常常通过这些通道信息来决断怎样传送数据流。

目前最常用的内部网关协议分别是：**路由信息协议（RIP）和最短路径优先路由协议（OSPF）分级的链接状态路由协议（ISIS）。**

2. **EGP：外部网关协议（Exterior Gateway Protocol）**

外部网关协议（EGP）是一种在**自治系统的相邻两个网关主机间交换路由信息的协议。** EGP 通常用于在因特网主机间交换路由表信息。它是一个轮询协议，利用 Hello 和 I-Heard-You 消息的转换，能让每个网关控制和接收网络可达性信息的速率，允许每个系统控制它自己的开销，同时发出命令请求更新响应。路由表包含一组已知路由器及这些路由器的可达地址以及路径开销，从而可以选择最佳路由。每个路由器每间隔 120 秒或 480 秒会访问其邻居一次，邻居通过发送完整的路由表以示响应，**代表协议是边界网关协议（BGPv4）**。

<img src="https://img-blog.csdnimg.cn/20200310175443430.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21vbm9sb2d1ZXpqcA==,size_16,color_FFFFFF,t_70" alt="img" style="zoom: 50%;" />

如果按照算法分，也可以分成两个大类：

**（1）距离矢量型路由协议：RIP**

**（2）链路状态路由协议：OSPF**

### II.RIP协议

RIP(Routing Information Protocol,路由信息协议）是一种内部网关协议（IGP），是一种**动态路由选择协议**，用于自治系统（AS）内的路由信息的传递。

**RIP 被定义为距离矢量路由协议**，而距离矢量路由协议的根本特征就是自己的**路由表是完全从其它路由器学来的**，并且将收到的路由条目一丝不变地放进自己的路由表，以供数据转发。正因为如此，**对于路由是否正确，对于目标是否可达，RIP全然不知。**

RIP 使用跳数作为距离单位，跳数就是到达目标网络所需要经过的路由器个数，因为直连网络不需要经过任何路由器，所以直连网络的跳数为 0。**RIP 所支持网络的最大跳数为 15**，一但大于 15，如 16，被 RIP 认为目标不可达，由此可见，RIP 并不适合大型网络。

**RIP协议一共有两个版本：**

- Version 1  有类路由协议，广播更新。（由于不支持VLSM，RIPV1已经被淘汰，以RIPv2为主）
- Version 2  无类路由协议，支持VLSM

**RIP是应用层协议， 使用 UDP 数据报传送**，端口号 520 将路由条目从开启了 RIP 进程的接口上发出，ver1 使用广播地**`255.255.255.255 `**发出，而 ver 2 使用组播地址 **`224.0.0.9`** 发出。

无论是 ver 1 还是 ver 2，都会将路由表每 30 秒定期向网络中发送，RIP 没有邻居的概念，所以自己并不知道发出去的路由更新是不是有路由器收到，而收到的路由更新，RIP 并不会绝对接受，**只有当路由的发送 IP 地址和自己接收的接口 IP 地址处于同网段时，才会接收，否则忽略。**如果路由表中的路由超过 180 秒都没有再次收到更新，则被标记为不可用，如果连续 240 秒没收到更新，最后将相应路由从路由表中删除。

| 版本 | RIPV1                   | RIPV2                      |
| ---- | ----------------------- | -------------------------- |
| 区别 | 有类路由协议            | 无类路由协议               |
|      | 广播更新255.255.255.255 | 组播更新224.0.0.9          |
|      | 不支持VLSM              | 支持VLSM                   |
|      | 自动路由汇总，不可关闭  | 自动汇总可关闭，可手动汇总 |
|      | 不支持不连续子网        | 支持不连续子网             |

**VLSM（可变长子网掩码）**： 是为了有效的使用无类别域间路由（CIDR）和路由汇聚(route summary)来控制路由表的大小，它是网络管理员常用的IP寻址技术，VLSM就是其中的常用方式，可以对子网进行层次化编址，以便最有效的利用现有的地址空间。

**RIP协议的三个要素：**
（1）仅和相邻路由器交换信息。
（2）交换的信息是当前本路由器所知道的全部信息，即自己的路由表。RIP交换的是本路由器上完整的路由表。
（3）按固定的时间间隔交换路由信息，例如，每隔 30 秒

### III.OSPF协议

#### :yellow_heart: 概述：

路由协议 OSPF 全称为 Open Shortest Path First，也就开放的最短路径优先协议，因为 OSPF 是由 IETF 开发的，它的使用不受任何厂商限制，所有人都可以使用，所以称为开放的，而最短路径优先（SPF）只是OSPF的核心思想，**其使用的算法是Dijkstra算法**，最短路径优先并没有太多特殊的含义，并没有任何一个路由协议是最长路径优先的，所有协议，都会选最短的。

距离矢量路由协议的根本特征就是自己的路由表是完全从其它路由器学来的，并且将收到的路由条目一丝不变地放进自己的路由表，运行距离矢量路由协议的路由器之间交换的是路由表，距离矢量路由协议是没有大脑的，路由表从来不会自己计算，总是把别人的路由表拿来就用；而 OSPF 完全抛弃了这种不可靠的算法，OSPF是典型的**链路状态路由协议**，**路由器之间交换的并不是路由表，而是链路状态**。**OSPF通过获得网络中所有的链路状态信息，从而计算出到达每个目标精确的网络路径。**

OSPF 工作在单个 AS，是个绝对的内部网关路由协议（Interior Gateway Protocol， 即 IGP）。

**OSPF 对网络没有跳数限制，支持 CIDR和VLSM**，没有自动汇总功能，但可以手工在任意比特位汇总，并且手工汇总没有任何条件限制，可以汇总到任意掩码长度。

OSPF 并不会周期性更新路由表，**而采用增量更新，即只在路由有变化时，才会发送更新**，并且只发送有变化的路由信息；事实上，OSPF **是间接设置了周期性更新路由的规则**，因为所有路由都是有刷新时间的，当达到刷新时间阀值时，该路由就会产生一次更新，默认时间为 1800 秒，即 30 分钟，所以 **OSPF 路由的定期更新周期默认为 30 分钟**。

OSPF 所有路由的管理距离(Ddministrative Distance)为 110，OSPF 只支持等价负载均衡。

OSPF 支持认证，并且支持明文和 MD5 认证；OSPF 不可以通过 Offset list 来改变路由的度量值（ metric）。

#### :dancers: 链路状态（Link-State）：

链路状态（LSA）就是 OSPF 接口上的描述信息，**例如接口上的 IP 地址，子网掩码，网络类型，Cost 值等等**，OSPF 路由器之间交换的并不是路由表，而是链路状态（LSA），OSPF 通过获得网络中所有的链路状态信息，从而计算出到达每个目标精确的网络路径。**OSPF 路由器会将自己所有的链路状态毫不保留地全部发给邻居，邻居将收到的链路状态全部放入链路状态数据库（Link-State Database），邻居再发给自己的所有邻居，并且在传递过程种，绝对不会有任何更改**。通过这样的过程，最终，网络中所有的 OSPF 路由器都拥有网络中所有的链路状态，并且所有路由器的链路状态应该能描绘出相同的网络拓朴。

**距离矢量路由中交换的是完整的路由表，这样如果有人恶意攻击的话，就能够知道整个网络拓扑结构。**而链路状态路由则交换链路的状态，用户无法通过这个清晰的得知整个链路拓扑。

比如现在要计算一条地铁线路图，如上海地铁二号线某段的图，如果不直接将该图给别人看，**图好比是路由表**，现在只是报给别人各个站的信息，该信息好比是链路状态，通过告诉别人各个站左边一站是什么，右边一站是什么，别人也能通过该信息（链路状态），画出完整的线路图（路由表），如得到如下各站信息（链路状态）：
    ★南京东路-站 （左边一站是人民广场，右边一站是陆家嘴）
    ★南京西路-站 （左边一站是静安寺，右边一站是人民广场）
    ★静安寺-站 （右边一站是南京西路）
    ★人民广场-站 （左边一站是南京西路，右边一站是南京东路）
    ★陆家嘴-站 （左边一站是南京东路）

## 4、网络层各种协议

### :alarm_clock: ARP协议：

ARP：地址解析协议（Address Resolution Protocol）。

由于存在网络层地址（IP）和链路层地址（MAC）地址，所以需要对它们进行转换。这就是ARP协议的任务。

传输一个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下一跳。然而，网络层的下一层是数据链路层，所以我们还要知道「下一跳」的 MAC 地址。

由于主机的路由表中可以找到下一跳的 IP 地址，所以可以通过 **ARP 协议**，求得**下一跳的 MAC 地址**。

:label: **ARP 是如何知道对方 MAC 地址呢？**

每台主机或路由器在内存中具有一张**ARP表，**这张表包含IP地址到MAC地址的映射关系。

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221028171656930.png" alt="image-20221028171656930" style="zoom:67%;" />

ARP 是借助 **ARP 请求与 ARP 响应**两种类型的包确定 MAC 地址的。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/34.jpg" alt="ARP 广播" style="zoom:67%;" />

- 首先，主机会构造一个称为ARP分组的特殊分组`（包括发送和接收IP地址以及MAC地址）`，通过**MAC广播地址`(FF-FF-FF-FF-FF-FF)`发送这个ARP 分组**，这个分组中包含了想要知道的 MAC 地址的主机 IP 地址。
- 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 **MAC 地址**塞入 **ARP 响应包**返回给主机。

另外，ARP是即插即用的，也就是说，一个ARP表是自动建立的，不需要系统管理员来配置，如果某台主机与子网断开连接，它的表项就会从ARP表中删除。

查询ARP报文是在广播帧中发送的，而响应ARP报文在一个标准帧中发送。

### :cloud_with_rain:RARP:

ARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是**已知 MAC 地址求 IP 地址**。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到，**让主机为其分配IP**。

通常这需要架设一台 `RARP` 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着：

- 该设备会发送一条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。
- RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。

最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/35.jpg" alt="RARP" style="zoom:67%;" />

### :family_man_man_girl_boy: DHCP协议

动态主机配置协议：DHCP`（Dynamic Host Configuration）`。

为本组织内的主机与路由器接口逐个分配IP地址。网络管理员能够配置DHCP，以使某主机每次与网络连接时都能获得同一个IP地址，或者某主机将被分配一个临时的IP地址，每次与网络连接时该地址也许是不同的。

**每个子网将具有一台DHCP服务器**，如果某个子网中没有服务器，则需要一个DHCP中继代理（通常为一台路由器），这个代理知道用于网络的DHCP服务器的地址。

主机通过 DHCP 动态获取 IP 地址的四个步骤：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/36.jpg" alt="DHCP 工作流程" style="zoom:67%;" />

- **DHCP服务发现：**客户端首先发起 **DHCP 发现报文（DHCP DISCOVER）** 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 **UDP 广播通信**，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。
- **DHCP服务提供：**DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文（DHCP OFFER）** 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 **IP 地址租用期**。
- **DHCP请求：**客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 **DHCP 请求报文（DHCP REQUEST）**进行响应，回显配置的参数。
- **DHCP ACK：**最后，服务端用 **DHCP ACK 报文**对 DHCP 请求报文进行响应，应答所要求的参数。

从移动性来看，DHCP存在缺陷，因为每当节点移动到一个新的子网，要从DHCP服务器获取一个新的IP地址，当一个节点在子网中移动时，就不能维持与远程应用的TCP连接了。

### :notebook_with_decorative_cover:NAT：

网络地址转换：NAT(`Network Address Translation`)：NAT是指通过将专用网络地址转换为公用地址，从而**对外隐藏内部管理的IP地址。**它使得**整个专用网只需要一个全球IP地址就可以与因特网连通**，由于专用网本地IP地址可以重用，因此NAT大大节省了IP地址的消耗。

IPv4 的地址是非常紧缺的，在前面我们也提到可以通过无分类地址来减缓 IPv4 地址耗尽的速度，但是互联网的用户增速是非常惊人的，所以 IPv4 地址依然有被耗尽的危险。

于是，提出了一种**网络地址转换 NAT** 的方法，再次缓解了 IPv4 地址耗尽的问题。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/38.jpg" alt="NAT" style="zoom:50%;" />

简单来说NAT就是当我们通过内网访问互联网时，把**局域网内的私有IP转换成互联网中的公有 IP 地址**。

有一个问题，如果从广域网到达NAT路由器的所有数据报都用相同的目的IP地址，那么路由器该怎样将这些数据报转发给内部主机呢？

使用NAT路由器上的**NAT转换表**，并且在表项中包含了**端口号和IP地址**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/39.jpg" alt="NAPT" style="zoom:50%;" />

如上图所示：**两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分。**

NAT转换表在 NAT 路由器上自动生成。例如，在 TCP 的情况下，建立 TCP 连接首次握手时的 **SYN 包一经发出，就会生成这个表**。而后又随着收到关闭连接时发出 **FIN 包的确认应答从表中被删除**。

:national_park:**NAT的缺陷**：

- 外部无法主动与 NAT 内部服务器建立连接，因为 NAT 转换表没有转换记录。
- 转换表的生成与转换操作都会产生性能开销。
- 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。

:kaaba:**如何解决以上缺陷**?

*第一种就是改用 IPv6*

IPv6 可用范围非常大，以至于每台设备都可以配置一个公有 IP 地址，IP地址保证够用，就不用搞NAP了。

*第二种 NAT 穿透技术*

在未使用NAT穿透时，**NAT路由器会将从外网发往内网的数据报丢弃**。NAT穿透技术可使发往具有某一特定IP和端口的应用都的数据报不被NAT路由设备（网关）屏蔽。

客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了。

### :lion:ICMP：

英特网控制报文协议：ICMP（`Internet Controlal Message Protocal`）

当运行一个HTTP会话时，我们可能遇到“目的网络不可达”等错误信息，这其实就是一种ICMP报文。

ICMP通常被认为是IP的一部分，但从体系结构上来说它是位于IP之上的，因为**ICMP报文是承载在IP分组中的**。

:card_file_box: **ICMP 的主要功能：**

`ICMP` 主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**

在 `IP` 通信中如果某个 `IP` 包因为某种原因未能达到目标地址，那么这个具体的原因将**由 ICMP 负责通知**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/40.jpg" alt="ICMP 目标不可达消息" style="zoom:50%;" />

**:zap: ICMP 类型：**

- 一类是用于诊断的查询消息，也就是「**查询报文类型**」
- 另一类是通知出错原因的错误消息，也就是「**差错报文类型**」

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/41.jpg" alt="常见的 ICMP 类型" style="zoom:50%;" />

:camel: **ICMP 包头格式：**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/5.jpg" alt="ICMP 报文" style="zoom:50%;" />

由上图可知，**ICMP是封装在IP包头之上的。**

### :bird: IGMP

在前面我们知道了组播地址，也就是 D 类地址，既然是**组播(多播)**，那就说明是只有一组的主机能收到数据包，不在一组的主机不能收到数组包，怎么管理是否是在一组呢？那么，就需要 `IGMP` 协议了。

**IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/42.jpg" alt="组播模型" style="zoom: 50%;" />

# 五、链路层

## 1.链路层概述

通信路径相邻节点的通信信道称为链路。

### :heart_decoration: **链路层提供如下服务**：

- 成帧：网络层数据报经过链路层传输前，它都要被链路层协议**封装成帧**，一个帧由一个数据字段和若干首部字段组成。
- 链路接入：**媒体访问控制**（Medium Access Control，MAC）协议规定了帧在链路上的传输规则。MAC协议用于协调多个节点的帧传输。
- 可靠交付：链路层协议提供可靠交付服务时，它保证网络层数据报经链路层无差错地移动。链路层可靠交付服务是通过确认与重传实现的。**可靠交付通常用于易于产生高差错率的链路**。对于低比特差错率的链路，一般不会提供可靠交付服务，所以，许多链路层协议是**不提供可靠交付服务**的。
- 差错检测和纠正：当帧中的一个比特作为1传输时，接收方节点中的链路层硬件可能不正确地将其判断为0.这种差错一般由**信号衰弱**和**电磁噪声**导致。许多链路层协议提供一种机制来进行差错检测和纠正，用**硬件来实现**，接收方不仅能检测帧中出现比特差错，而且能够准确地确认帧中差错出现的位置。

### :vs: **链路层实现的位置**:

链路层的主体部分是在**网络适配器（网络接口卡）**实现的。越来越多的网络适配器被综合进主机的主板，即所谓的局域网在主板配置。

链路层是**硬件和软件的结合体**，链路层的软件部分实现了高层链路层的功能，如组装链路层寻址信息和激活控制器硬件，在接收端，链路层软件响应控制器中断，处理差错条件和将数据报向上层传递给网络层。

### :nail_care: 链路层差错检测和纠正技术：

- 奇偶校验
- 英特网检验和
- 循环冗余检测

## 2.多路访问链路和协议

### :jack_o_lantern:**基本概念**：

- 广播链路：能够让多个发送和接收节点都连接到相同的，共享的**广播信道**上。当一个节点传输一个帧时，信道广播该帧，广播链路中的其它节点都将收到一个该帧的副本。

- 多路访问问题：**协调多个发送和接收节点对一个共享广播信道的访问**。广播信道通常用于局域网中（大学、公司等）。

- 多路访问协议：通过这些协议来规范节点在广播信道上的传输行为。

### :v: **多路访问协议的分类**：

- 信道划分协议
- 随机接入协议
- 轮流协议

#### :laughing:信道划分协议：

**I.时分多路复用（TDM）**：将时间划分为时间帧，并进一步将，每个事件帧划分为N个时隙（时间片）。然后把每个时隙分给N个节点（用户）中的一个。

该协议**消除了碰撞并且很公平**：每个节点传输速率均为 `(信道传输速率 / N )`bps。

但存在**两个缺陷：**

- 节点传输速率受限，即使只有一个节点，速率也是固定的
- 节点必须等待它在传输序列中的轮次，传输效率低下

<img src="https://www.educity.cn/article_images/2014-01-27/6a3f100b-3612-416d-8ede-e4f5cef4aa86.jpg" alt="查看源图像" style="zoom: 80%;" />

**II.频分多路复用（FDM）**：频率域被划分为固定大小的频段，每条电路连续地得到部分带宽。

![查看源图像](https://www.educity.cn/article_images/2014-01-27/6f426e9f-a8d5-4c27-ad97-8695b911af99.jpg)

**III.码多分址（CDMA）**：CDMA为每个节点分配一种不同的编码，然后每个节点用它的唯一编码来对它发送的数据进行编码，因此各个节点在传输数据时不会互相干扰。这些编码能够使不同的节点同一时间传输数据。

#### :hatched_chick:**随机接入协议**：

在随机接入协议中，一个传输节点总是以信道的全部速率（R bps）进行发送。当由碰撞时，涉及碰撞的每个节点反复重发它的帧，知道无碰撞地通过为止。

**I.时隙ALOHA：**

- 当一个节点有一个新的帧要发送时，等到下一个时隙A开始，直接在A时隙传输整个帧
- 如果无碰撞，则传输成功，准备下一个帧
- 如果发生碰撞，在该时隙结束之前检测到碰撞。以概率p在后续的时隙中重传
- 对于N个节点的链路，给定一个节点传输的概率为p，则任何一个节点成功传送的概率为 `Np（1 - p）^(N-1)`

**II.ALOHA：**

- 这时一个非时隙的完全分散的协议，当网络层数据报被封装成帧，立即将该帧传输到广播信道，与时隙ALOHA相比传输效率更低
- 如果发生碰撞，立即以概率p重传该帧，否则将进行一个帧传输时间的等待
- 等待结束之后，以概率p重传，或者以概率1-p在另一个帧传输时间等待

**III.载波侦听多路访问（CSMA）：**

- 载波侦听：传输前，先侦听信道，若信道空闲则发送，忙则等待
- 碰撞检测：传输中，一直侦听信道，若检测到另一个节点正在传输干扰帧，就停止传输，进入载波侦听状态

**IV.具有碰撞检测的多路载波侦听多路访问（CSMA/CD）**

- 先侦听后传输，信道空闲则发送，忙则等待
- 碰撞检测：传输中，一直侦听信道，若检测到另一个节点正在传输干扰帧，碰撞即停
- 二进制指数后退：当发生一次碰撞时，节点随机从集合{0，1，2，……，2^n - 1}中选择一个K值等待K*512比特时间（发送512bit进入以太网所需的时间）后重传，n的最大值为10。
- 多次碰撞，直接放弃发送

### :japanese_ogre:轮流协议：

**多路访问协议有两个理想特性：**

- 当只有一个节点活跃时，具有R bps的吞吐量
- 当有M个节点活跃时，具有接近R/M bps的吞吐量

ALOHA和CSMA具备第一特性但**不具备第二特性**。

**I.轮询协议：**

- 要求节点之一被指定为主节点，主节点以循环的方式轮询每个节点。
- 主节点首先向节点1发送一条报文，该报文是通知节点1能够传输的最多数量为M的帧，当节点1传输完某些帧后，主节点有通知节点2能够传输的最多数量为N的帧。
- 主节点通过观察在信道上是否缺乏某信号，来决定一个节点何时完成了帧的发送。

**缺点：**

- 引入了轮询通知的时延
- 主节点故障，整个信道不可用



**II.令牌传递协议：**

- 该协议无主节点，一个称为**令牌**（token）的小的特殊帧在节点之间以某种固定次序进行交换
- 当一个节点收到令牌时，如果它有数据要发送，则持有此令牌直至发送完毕，否则立即向下一节点转发该令牌

**缺点：**

- 一个持有令牌的节点发生故障可能会使整个信道崩溃
- 如果某一节点偶尔忘记释放令牌，需要调用某种恢复步骤使令牌返回到循环中来

## 3.交换局域网

### :sailboat:MAC地址：

- 主机或路由器上的网络适配器具有链路层地址。具有多个网络接口的主机或路由器具有多个链路层地址，链路层地址有多种叫法：**LAN地址、物理地址或MAC地址（最常用的叫法）。**
- 对于大多数局域网（以太网和802.11无线局域网）而言，**MAC地址长度为6字节（`48bit`）**
- MAC地址是唯一的，是**网络适配器生产出来就固定下来的**。MAC地址具有扁平化结构，一个MAC地址就标识一个网络接口，而IP地址是层次化的，即可以分为网络号和主机号
- 当某个适配器要向别的适配器发送一个帧时，需要将目的适配器的MAC地址插入到帧中，并将该帧发送到局域网
- 有些时候发送方适配器需要局域网中所有适配器接收它发送的某个帧，发送适配器需要在该帧的目的地址字段中插入一个特殊的MAC广播地址（FF-FF-FF-FF-FF-FF）。

### :yen:以太网：

- 以太网是当今**最为流行的有线局域网技术**，它很大程度上取代了其他局域网标准。如令牌环、FDDI和ARCNET。
- 以太网是建立在**CSMA/CD**`(具有碰撞检测的多路载波侦听多路访问)`机制上的**广播型网络**。
- 所有的以太网技术都向网络层提供**无连接服务**：即适配器A要向适配器B发送一个数据报时，没有先与适配器B握手
- 以太网技术都向网络层提供**不可靠服务**：当适配器B收到来自适配器A的帧，对该帧进行循环冗余检验，即使通过检验收到该帧，它也不会发送确认帧；如果未通过，直接丢弃，对方是不知道自己发送的帧是否被正确接收的。

:dango:**以太网帧结构**：

![img](https://img-blog.csdnimg.cn/20190715212335720.png)

DMAC（Destination MAC）是**目的MAC地址**。DMAC字段长度为6个字节，标识帧的接收者。

SMAC（Source MAC）是**源MAC地址**。SMAC字段长度为6个字节，标识帧的发送者。

类型字段（Type）用于标识数据字段中包含的高层协议，该字段长度为2个字节。类型字段取值为**0x0800**的帧代表**IP协议帧**；类型字段取值为**0x0806**的帧代表**ARP协议帧**。

数据字段(Data)是网络层数据，承载了IP数据报，最小长度必须为46字节以保证帧长至少为64字节，数据字段的最大长度为1500字节。

循环冗余校验字段（FCS）提供了一种错误检测机制。该字段长度为4个字节。


### :kick_scooter:**链路层交换机**：

- 交换机的任务是**接收入链路层帧并将它们转发出链路**。
- 交换机自身对于子网中的主机和路由器是**透明的**，即帧发送的寻址是以主机/路由器为单位的，它们并不知道某交换机会接收该帧并转发到另节点，交换机相当于一个透明中间人，默默付出传递消息。
- 帧到达交换机的任一接口的速率可能会暂时超出该接口的链路容量，所以在交换机的输出端口设有缓存。

#### :hugs:**1.交换机转发和过滤：**

过滤：对传送到该交换机输入接口的帧进行判断，丢弃还是接收

转发：决定一个帧该被导向哪个输出接口，并把该帧移动到那个接口

交换机的转发和过滤是借助于**交换机表**（`switch table`）来完成的。

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221029145322455.png" alt="image-20221029145322455" style="zoom:80%;" />

假设一个**目的MAC地址**为CC-CC-CC-CC-CC-CC的帧发送到x接口：

- 盲目转发：对于表项中不存在的目的MAC地址的帧，交换机广播该帧，即**向所有接口转发**。
- 明确丢弃：如果表项中存在该地址，但输出接口y=x，则执行过滤，直接丢弃该帧
- 明确转发：如果表项中存在该地址，但输出接口**y!=x**，则执行转发

#### :parasol_on_ground:**2.自学习**

交换机表是自动，动态自治建立的，不需要网络管理员来手动配置，即交换机是**自学习**的。

**自学习以如下方法实现：**

- 交换机表初始化为空
- 对于每个接口接收到的每个入帧，该交换即在其表中记录下：该帧的源MAC地址、该帧到达的接口、当前时间。交换机以这种方式在它的表中记 录发送节点所在LAN网段。若在LAN上的每个节点最终都发送了一个帧，则每个节点将在这张表中被记录下来。
- 如果在一段时间(称为老化期(aging time)后，交换机没有接收到以该址作为源地址的帧，就在表中删除这个地址

#### :calendar:3.**交换机的转发和自学习工作流程：**

（1）A到B
帧由主机A出发到接口1，交换机在帧交换表中登记，之后查询目的MAC地址，找不到，于是从其他接口转发出去，最后通过3接口找到主机B。其他的主机都不匹配。

<img src="https://img-blog.csdnimg.cn/20200514233704675.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbmdfZmF5ZQ==,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />

（2）B到A
帧从主机B出发到接口3，交换机在帧交换表中登记，之后查询目的MAC地址，找到MAC地址为A，接口为1，于是从1接口转发出去到达主机A。

<img src="https://img-blog.csdnimg.cn/20200514233704695.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbmdfZmF5ZQ==,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />

（3）E到A
帧从主机E出发到接口3，交换机2在帧交换表中登记，之后查询目的MAC地址，找到MAC地址为A，接口为2，于是从2出去，到交换机1的接口4，交换机1在帧交换表中登记，之后查询目的MAC地址，找到MAC地址为A，接口为1，于是从1接口转发出去到达主机A。

<img src="https://img-blog.csdnimg.cn/20200514233704775.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbmdfZmF5ZQ==,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />

（4）G到A
帧从主机G出发到接口1，交换机在帧交换表中登记，之后查询目的MAC地址，找到MAC地址为A，接口为1，发现和进来的是同一个接口于是将帧丢弃。

<img src="https://img-blog.csdnimg.cn/20200514233704954.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbmdfZmF5ZQ==,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />

（5）

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221029151836756.png" alt="image-20221029151836756" style="zoom:67%;" />

#### :sandal: 4.链路层交换机的性质：

- 消除碰撞：交换机缓存帧并且绝不会再网段上同时传输多余一个帧
- 异质链路：交换机将链路彼此隔离，因此局域网中的不同链路能够以不同速率运行在不同媒体上
- 管理：易于进行网络管理，并且安全性高

#### :diamond_shape_with_a_dot_inside:5.交换机与路由器的区别：

:satellite:***工作方式不同*：**

- 路由器：寻址，转发（依靠 IP 地址）
- 交换机：过滤，转发（依靠 MAC 地址）

我们可以看出这两者的主要工作就是转发数据，但是不同之处是，依靠的地址不同，这是一个根本区别！

- **路由器**内有一份**路由表**，里面有它的寻址信息（就像是一张地图），它收到网络层的数据报后，会根据路由表和选路算法将数据报转发到下一站（可能是路由器、交换机、目的主机）
- **交换机**内有一张**交换机表**（MAC表），里面存放着和它相连的所有设备的MAC地址。

***:champagne: 工作范围不同：***

![img](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMDIxMTY1ODQ3NTk5?x-oss-process=image/format,png)

**每一个路由器与其之下连接的设备，其实构成一个局域网**
交换机工作在路由器之下，就是也就是**交换机工作在局域网内**
交换机用于**局域网内网的数据转发**
路由器用于**连接局域网和外网**

:balance_scale: ***工作内容不同：***

- 路由器可作为网关，提供防火墙功能
- 交换机不能提供这些功能，交换机只是做端口扩展，扩大局域网的接入点，而路由器能实现局域网间互联

### :telephone:虚拟局域网：

#### I.基本概念

**虚拟局域网（VLAN**）是一组逻辑上的设备和用户，这些设备和用户并不受物理位置的限制，可以根据功能、部门及应用等因素将它们组织起来，相互之间的通信就好像它们在同一个网段中一样，由此得名虚拟局域网。VLAN是一种比较新的技术，工作在OSI参考模型的第2层和第3层，**一个VLAN就是一个广播域**，**VLAN之间的通信是通过第3层的路由器来完成的。广播域，指的是广播帧（目标MAC地址全部为1）所能传递到的范围，亦即能够直接通信的范围。**

<img src="https://img-blog.csdn.net/20130726174341921" alt="img" style="zoom:67%;" />

<img src="https://img-blog.csdn.net/20130726174436734" alt="img" style="zoom:67%;" />

**二层交换机只能构建单一的广播域**，不过使用VLAN功能后，它能够**将网络分割成多个广播域**。如果仅有一个广播域，有可能会影响到网络整体的传输性能。

#### II.为什么需要VLAN：

分割广播域时，一般都**必须**使用到路由器。使用路由器后，可以以**路由器上的网络接口（LAN Interface）为单位**分割广播域。

但是，通常情况下路由器上不会有太多的网络接口，其数目多在1～4个左右。

与路由器相比，**二层交换机一般带有多个网络接口。**因此如果能使用它分割广播域，那么无疑运用上的灵活性会大大提高。

用于在**二层交换机上分割广播域的技术**，就是***VLAN***。通过利用VLAN，我们可以自由设计广播域的构成，提高网络设计的自由度。

#### III.虚拟局域网（VLAN）的实现：

首先，在一台**未设置任何VLAN**的二层交换机上，**任何广播帧都会被转发给除发送端口外的所有其他端口**。

这时，如果在交换机上**生成红、蓝两个VLAN**，比如C发送广播信息时，只会被转发给其他属于蓝色VLAN的端口，不会被转发给属于红色VLAN的端口。

就这样，VLAN通过**限制**广播帧转发的范围**分割**了广播域。上图中为了便于说明，以红、蓝两色识别不同的VLAN，在实际使用中则是用“**VLAN ID**”来区分的。

![img](https://img-blog.csdn.net/20130726174753812)

要更为直观地描述VLAN的话，我们可以把它理解为将一台交换机在**逻辑上分割成了数台交换机**。在一台交换机上生成红、蓝两个VLAN，也可以看作是将一台交换机换做一红一蓝两台虚拟的交换机。

<img src="https://img-blog.csdn.net/20130726174827609" alt="img" style="zoom:67%;" />

但是，VLAN生成的**逻辑**上的交换机是**互不相通**的。因此，在交换机上设置VLAN后，如果未做其他处理，VLAN间是无法通信的。

如何实现不同的VLAN间通信呢？

VLAN是广播域。而**通常两个广播域之间由路由器连接**，广播域之间来往的数据包都是由**路由器中继**的。因此，**VLAN间的通信也需要路由器提供中继服务**，这被称作“**VLAN间路由**”。VLAN间路由，可以使用普通的路由器，也可以使用三层交换机。

# 六、大总结-Web页面请求流程

**场景：我们进入一个局域网，连上网线，打开PC，然后打开浏览器键入一串URL……**

### :camping: 准备阶段：DHCP、UDP、IP、以太网

1. PC的OS生成一个DHCP请求报文，并将DHCP报文放入具有目的端口67（DHCP服务器）和源端口68（DHCP客户端）的**UDP报文段。**该 UDP报文段被放置在一个具有广播IP目的地址地址（255.255.255.255）和源IP地址为0.0.0.0的IP数据报**（DHCP发现报文）**中。
2. DHCP请求报文的IP数据报则被PC的网卡封装为**以太网帧，**然后将该帧以目的地址为FF-FF-FF-FF-FF-FF的广播地址广播出去
3. DHCP服务器收到该发现报文后对客户端发送**DHCP提供报文**，该报文仍用IP广播地址（255.255.255.255）发送，客户端收到某服务器的DHCP提供报文后，向DHCP服务器发送**DHCP请求报文**。
4. 最后DHCP用DHCP ACK报文回复PC，应答其请求参数，这时，PC在该局域网内就获得了一个IP地址。

### :e-mail: 浏览器服务器交互阶段：DNS、TCP、HTTP

#### **step1：url解析：**

- 首先浏览器做的第一步工作就是要对 `URL` 进行解析，从而生成发送给 `Web` 服务器的请求信息。
- 假设url为：http://www.server.com/dir/file1.html (协议名 + 主机名 + 文件路径名)
- 如果主机名为域名，则需要先查询本地缓存，是否有域名和IP地址的映射，如果没有则请求，DNS服务器以查询出域名对应的IP地址
- 当没有路径名时，就代表访问根目录下事先设置的**默认文件**，也就是 `/index.html` 或者 `/default.html`

#### **step2：生产 HTTP 请求信息：**

对 `URL` 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息了。

<img src="C:\Users\龚chang\AppData\Roaming\Typora\typora-user-images\image-20221029171147539.png" alt="image-20221029171147539" style="zoom:80%;" />

#### **step3：将HTTP请求报文交付给传输层：**

> I.TCP 传输数据之前，要先三次握手建立连接

在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为**三次握手**。

- 一开始，客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口**（`listen()`）**，处于 `LISTEN` 状态。
- 然后客户端主动发起连接 `SYN`**(调用connect()函数)**，之后处于 `SYN-SENT` 状态。
- 服务端收到发起的连接(**调用accept()函数**)，返回 `SYN`，并且 `ACK` 客户端的 `SYN`，之后处于 `SYN-RCVD` 状态。
- 客户端收到服务端发送的 `SYN` 和 `ACK` 之后，发送对 `SYN` 确认的 `ACK`(**从connect()返回**)，之后处于 `ESTABLISHED` 状态，因为它一发一收成功了。
- 服务端收到 `ACK` 的 `ACK` 之后，处于 `ESTABLISHED` 状态(**从accept()函数返回**)，因为它也一发一收了。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="TCP 三次握手" style="zoom:50%;" />

> II.TCP 分割数据

如果 HTTP 请求消息比较长，超过了 `MSS` 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。

> III.TCP 报文生成

TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 `80`， HTTPS 默认端口号是 `443`）。

在双方建立了连接后，TCP 报文中的数据部分就是存放 **HTTP 头部 + 数据，组装好 TCP 报文之后，就需交给下面的网络层处理**。

#### step4：将TCP报文段交付给网络层

:angel:**填充IP报文头：**

TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托网络层**IP 模块**将数据封装成**网络包**发送给通信对象。

在 IP 协议里面需要有**源地址 IP 和 目标地址 IP**，因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的**协议号**，要填写为 `06`（十六进制），表示协议为 TCP。之后要将TCP数据报封装成IP分组发向链路层。

- 源地址IP，即是客户端输出的 IP 地址；
- 目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。

由于一个MAC地址对应一个网卡IP地址，当存在多个网卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断**应该使用哪个一块网卡来发送包**。

这个时候就需要根据**路由表**规则，来判断**哪一个网卡作为源地址 IP**。

在 Linux 操作系统，我们可以使用 `route -n` 命令查看当前系统的路由表。

```shell
[root@gcs101 bin]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.244.2   0.0.0.0         UG    100    0        0 ens33
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
172.18.0.0      0.0.0.0         255.255.0.0     U     0      0        0 br-8761d05d38dc
192.168.122.0   0.0.0.0         255.255.255.0   U     0      0        0 virbr0
192.168.244.0   0.0.0.0         255.255.255.0   U     100    0        0 ens33
```

根据上面的路由表，我们将目标IP地址与表项中的子网掩码做与运算，计算出的值如果能匹配`Destination`，那么将使用 匹配上的表项中`Use Iface`的 IP 地址作为 IP 包头的源地址。

第一条目比较特殊，它目标地址和子网掩码都是 `0.0.0.0`，这表示**默认网关**，如果**其他所有条目都无法匹配，就会自动匹配这一行**。并且后续就把包发给路由器，`Gateway` 即是**路由器的 IP 地址。**路由器将根据一系列路由选择算法来决定它要将数据报发送到哪一台路由器或主机上。 

:ice_cream: **IP 报文生成：**

ip报文首部填充完毕后，将TCP报文和IP报文头封装就生成了IP报文，转发到网卡。

### :flags: 报文准备离家前的最后准备—— MAC

生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 **MAC 头部**。

在 MAC 包头里需要**发送方 MAC 地址**和**接收方目标 MAC 地址**，用于**两点之间的传输**。

一般在 TCP/IP 通信里，MAC 包头的**协议类型**只使用：

- `0800` ： IP 协议
- `0806` ： ARP 协议

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/18.jpg" alt="MAC 包头格式" style="zoom:67%;" />

发送方的MAC地址很容易知道，这时网卡生产后就写死的。要解决的就是如何获取接收方MAC地址的问题：

在路由器或主机中，OS维护着一张ARP表，记录着IP地址与MAC地址的映射关系

在 Linux 系统中，我们可以使用 `arp -a` 命令来查看 ARP 缓存的内容。

```shell
[root@gcs101 bin]# arp
Address                  HWtype  HWaddress           Flags Mask            Iface
gcs102                           (incomplete)                              ens33
gcs100                           (incomplete)                              ens33
gateway                  ether   00:50:56:f1:1c:67   C                     ens33
172.18.0.6               ether   02:42:ac:12:00:06   C                     br-8761d05d38dc
172.18.0.4               ether   02:42:ac:12:00:04   C                     br-8761d05d38dc
172.18.0.5               ether   02:42:ac:12:00:05   C                     br-8761d05d38dc
172.18.0.2               ether   02:42:ac:12:00:02   C                     br-8761d05d38dc
172.18.0.3               ether   02:42:ac:12:00:03   C                     br-8761d05d38dc
```

在填充MAC头部目标MAC地址之前，会先查询ARP表，如果有则直接填写，否则发送方主机会构造一个称为ARP分组的特殊分组`（包括发送和接收IP地址以及MAC地址）`，通过**MAC广播地址`(FF-FF-FF-FF-FF-FF)`广播这个ARP 分组**，这个分组中包含了想要知道的 MAC 地址的主机 IP 地址。如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。

### :satisfied: 报文离开主机，进入链路

网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将**数字信息转换为电信号**，才能在网线上传输，也就是说，这才是真正的数据发送过程。

负责执行这一操作的是**网卡**，要控制网卡还需要靠**网卡驱动程序**。

网卡驱动获取网络包之后，会将其**复制**到网卡内的缓存区中，接着会在其**开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/%E6%95%B0%E6%8D%AE%E5%8C%85.drawio.png" alt="数据包" style="zoom:67%;" />

- 起始帧分界符是一个用来表示包起始位置的标记
- 末尾的 `FCS`（帧校验序列）用来检查包传输过程是否有损坏

最后**网卡会将包转为电信号，通过网线发送出去**。